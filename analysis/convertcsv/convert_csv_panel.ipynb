{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nordb\\AppData\\Local\\Temp\\ipykernel_8532\\2314209265.py:12: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  timestamps = pd.Int64Index(timestamps, dtype=np.int64)\n",
      "C:\\Users\\nordb\\AppData\\Local\\Temp\\ipykernel_8532\\2314209265.py:12: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  timestamps = pd.Int64Index(timestamps, dtype=np.int64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([1, 2, 3, 4, 5, 6, 7, 8], dtype='int64')\n",
      "MultiIndex([('simple1', 1),\n",
      "            ('simple1', 2),\n",
      "            ('simple1', 3),\n",
      "            ('simple1', 4),\n",
      "            ('simple1', 5),\n",
      "            ('simple1', 6),\n",
      "            ('simple1', 7),\n",
      "            ('simple1', 8)],\n",
      "           names=['instances', 'timepoints'])\n",
      "Int64Index([1, 2, 3, 4, 5, 6, 7, 8], dtype='int64')\n",
      "MultiIndex([('simple1', 1),\n",
      "            ('simple1', 2),\n",
      "            ('simple1', 3),\n",
      "            ('simple1', 4),\n",
      "            ('simple1', 5),\n",
      "            ('simple1', 6),\n",
      "            ('simple1', 7),\n",
      "            ('simple1', 8)],\n",
      "           names=['instances', 'timepoints'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>first</th>\n",
       "      <th>second</th>\n",
       "      <th>third</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instances</th>\n",
       "      <th>timepoints</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">simple1</th>\n",
       "      <th>1</th>\n",
       "      <td>312</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>345</td>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>355</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>355</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>356</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>354</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>355</td>\n",
       "      <td>1</td>\n",
       "      <td>654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>356</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      first  second  third\n",
       "instances timepoints                      \n",
       "simple1   1             312       0     45\n",
       "          2             345       0     87\n",
       "          3             355       0     23\n",
       "          4             355       0     67\n",
       "          5             356       1     12\n",
       "          6             354       1      3\n",
       "          7             355       1    654\n",
       "          8             356       2      4"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sktime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def readcsv(csv_loc:str, name:str):\n",
    "    csv = pd.read_csv(csv_loc)\n",
    "\n",
    "    # print(csv.to_string())\n",
    "    metrics = csv[\"identifier\"].to_list()\n",
    "    timestamps = csv.columns[1:].to_flat_index()\n",
    "    timestamps = timestamps.to_numpy().tolist()\n",
    "    timestamps = pd.Int64Index(timestamps, dtype=np.int64)\n",
    "    print(timestamps)\n",
    "    index = pd.MultiIndex.from_product([[name], timestamps], names=['instances','timepoints'])\n",
    "    print(index)\n",
    "    vals = csv.drop(labels=\"identifier\",axis=1).to_numpy().transpose()\n",
    "    s = pd.DataFrame(vals, index=index, columns=metrics)\n",
    "    return s\n",
    "\n",
    "\n",
    "\n",
    "simple = readcsv(\"../Test_datasets/simple1.csv\", \"simple1\")\n",
    "simple2 = readcsv(\"../Test_datasets/simple2.csv\", \"simple1\")\n",
    "from sktime.transformations.panel.rocket import Rocket\n",
    "\n",
    "rocket = Rocket()\n",
    "rocket.fit(simple)\n",
    "rocket.fit(simple2)\n",
    "simple\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below is my some code I will use for formatting unix timestamps to datetimeIndex, not relevant  ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 10 13 0.1 9.0 75.0 0.2 8.0 1.0 0.22 7.0 0.5 0.3 6.0 24.0 0.3 5.0 7.0\n",
      " 0.3 4.0 5.0 0.4 3.0 23.0 0.5 3.0 56.0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instances</th>\n",
       "      <th>timepoints</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">increase</th>\n",
       "      <th>2023-01-18 12:32:47</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-18 12:32:52</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-18 12:32:57</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-18 12:33:02</th>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-18 12:33:07</th>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-18 12:33:12</th>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-18 12:33:17</th>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-18 12:33:22</th>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-18 12:33:27</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">decrease</th>\n",
       "      <th>2023-01-18 12:32:47</th>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-18 12:32:52</th>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-18 12:32:57</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-18 12:33:02</th>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-18 12:33:07</th>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-18 12:33:12</th>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-18 12:33:17</th>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-18 12:33:22</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-18 12:33:27</th>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">neither</th>\n",
       "      <th>2023-01-18 12:32:47</th>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-18 12:32:52</th>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-18 12:32:57</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-18 12:33:02</th>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-18 12:33:07</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-18 12:33:12</th>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-18 12:33:17</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-18 12:33:22</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-18 12:33:27</th>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  0\n",
       "instances timepoints               \n",
       "increase  2023-01-18 12:32:47     0\n",
       "          2023-01-18 12:32:52    10\n",
       "          2023-01-18 12:32:57    13\n",
       "          2023-01-18 12:33:02   0.1\n",
       "          2023-01-18 12:33:07   9.0\n",
       "          2023-01-18 12:33:12  75.0\n",
       "          2023-01-18 12:33:17   0.2\n",
       "          2023-01-18 12:33:22   8.0\n",
       "          2023-01-18 12:33:27   1.0\n",
       "decrease  2023-01-18 12:32:47  0.22\n",
       "          2023-01-18 12:32:52   7.0\n",
       "          2023-01-18 12:32:57   0.5\n",
       "          2023-01-18 12:33:02   0.3\n",
       "          2023-01-18 12:33:07   6.0\n",
       "          2023-01-18 12:33:12  24.0\n",
       "          2023-01-18 12:33:17   0.3\n",
       "          2023-01-18 12:33:22   5.0\n",
       "          2023-01-18 12:33:27   7.0\n",
       "neither   2023-01-18 12:32:47   0.3\n",
       "          2023-01-18 12:32:52   4.0\n",
       "          2023-01-18 12:32:57   5.0\n",
       "          2023-01-18 12:33:02   0.4\n",
       "          2023-01-18 12:33:07   3.0\n",
       "          2023-01-18 12:33:12  23.0\n",
       "          2023-01-18 12:33:17   0.5\n",
       "          2023-01-18 12:33:22   3.0\n",
       "          2023-01-18 12:33:27  56.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import sktime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def readcsv(csv_loc:str):\n",
    "    csv = pd.read_csv(csv_loc).transpose()\n",
    "    metrics = csv.loc[\"identifier\"].to_list()\n",
    "    timestamps = pd.DatetimeIndex(np.array(csv.index[1:].astype('int').tolist(), dtype='datetime64[s]'))\n",
    "    print(csv.values[1:].flatten())\n",
    "    vals = csv.values[1:].flatten()\n",
    "    index = pd.MultiIndex.from_product([metrics, timestamps], names=['instances','timepoints'])\n",
    "    s = pd.DataFrame(vals, index=index)\n",
    "    return s\n",
    "    # metrics = csv[\"identifier\"].to_list()\n",
    "    # timestamps = csv.columns[1:].to_flat_index()\n",
    "    # timestamps = timestamps.to_numpy().tolist()\n",
    "    # timestamps = pd.Int64Index(timestamps, dtype=np.int64)\n",
    "    \n",
    "    # index = pd.MultiIndex.from_product([metrics, timestamps], names=['instances','timepoints'])\n",
    "    # vals = csv.drop(labels=\"identifier\",axis=1).to_numpy().flatten()\n",
    "    # s = pd.DataFrame(vals, index=index)\n",
    "    # return s\n",
    "\n",
    "\n",
    "\n",
    "simple = readcsv(\"../DTW/testing.csv\")\n",
    "simple\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195510 195510\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def merge_with_new(existing_vals:pd.DataFrame, new_vals:pd.DataFrame) -> np.ndarray :\n",
    "    common_columns = existing_vals.columns.intersection(new_vals.columns)\n",
    "    reduced_existing = existing_vals.reindex(columns=common_columns)\n",
    "    reduced_new = new_vals.reindex(columns=common_columns)\n",
    "    timestamps = reduced_existing.index.get_level_values(1)\n",
    "\n",
    "    row = existing_vals.iloc[(slice(None),0)]\n",
    "    print(row.index)\n",
    "    \n",
    "    newnames = reduced_new.index.get_level_values(0).drop_duplicates()\n",
    "    oldnames = reduced_existing.index.get_level_values(0).drop_duplicates()\n",
    "    combined_names = oldnames.union(newnames)\n",
    "\n",
    "    tuples = [(i,j) for i in combined_names for j in timestamps]\n",
    "    index = pd.MultiIndex.from_tuples(tuples)\n",
    "\n",
    "    reduced_combined = pd.concat([reduced_existing,reduced_new],axis=0)\n",
    "    reduced_combined = reduced_combined.set_index(index)\n",
    "    #remove any columns that exists in one but not the other\n",
    "    return reduced_combined\n",
    "\n",
    "def make_datetime_index(timestamps:list) -> pd.DatetimeIndex:\n",
    "    beginning = timestamps[0]\n",
    "    end = timestamps[-1]\n",
    "    beginning, end = pd.to_datetime((beginning,end), unit=\"s\")\n",
    "    index = pd.date_range(start=beginning, end=end, periods=len(timestamps))\n",
    "    return index\n",
    "\n",
    "def concat_dfs(old:pd.DataFrame, new:pd.DataFrame) -> pd.DataFrame:\n",
    "    unioned = old.index.union(new.index)\n",
    "    concated = pd.concat([old.reindex(unioned), new.reindex(unioned)])\n",
    "    return concated\n",
    "\n",
    "def readcsv(csv_loc:str, num:int):\n",
    "    csv = pd.read_csv(csv_loc)\n",
    "    metrics = csv[\"identifier\"].to_list()\n",
    "    timestamps = csv.columns[1:].to_flat_index()\n",
    "    timestamps = timestamps.to_numpy().tolist()\n",
    "    timestamps = make_datetime_index(timestamps)\n",
    "    index = pd.MultiIndex.from_product([[num], timestamps], names=['instances','timepoints'])\n",
    "    vals = csv.drop(labels=\"identifier\",axis=1).to_numpy().transpose()\n",
    "    s = pd.DataFrame(vals, index=index, columns=metrics)\n",
    "    return s\n",
    "\n",
    "def readcsv_modified(csv_loc:str):\n",
    "    csv = pd.read_csv(csv_loc)\n",
    "    metrics = csv[\"identifier\"].to_list()\n",
    "    timestamps = csv.columns[1:].to_flat_index()\n",
    "    timestamps = timestamps.to_numpy().tolist()\n",
    "    timestamps = make_datetime_index(timestamps)\n",
    "   # index = pd.MultiIndex.from_product([[num], timestamps], names=['instances','timepoints'])\n",
    "    vals = csv.drop(labels=\"identifier\",axis=1).to_numpy().transpose()\n",
    "    s = pd.DataFrame(vals, index=timestamps, columns=metrics)\n",
    "    return s\n",
    "\n",
    "def removeNaNs(df:pd.DataFrame) -> pd.DataFrame:\n",
    "    for col in df.columns:\n",
    "        if df[col].isna().any():\n",
    "            df = df.drop(col, axis=1)\n",
    "    return df\n",
    "\n",
    "def removeUniqueColumns(first:pd.DataFrame, second:pd.DataFrame) -> tuple:\n",
    "    common_columns = first.columns.intersection(second.columns)\n",
    "    reduced_old = first.reindex(columns=common_columns)\n",
    "    reduced_new = second.reindex(columns=common_columns)\n",
    "    return reduced_old, reduced_new\n",
    "\n",
    "def removeUniqueColumns2(frames:list) -> list:\n",
    "    template:pd.DataFrame = frames[0]\n",
    "    #Round 1: Reduces the first frame to be the smallest size to match with everyone\n",
    "    for frame in frames[1:]:\n",
    "        common_columns = template.columns.intersection(frame.columns)\n",
    "        template = template.reindex(columns=common_columns)\n",
    "    returnlist = [template]\n",
    "    #Round 2: Reduces all the other ones to the same minimum\n",
    "    for frame in frames[1:]:\n",
    "        common_columns = template.columns.intersection(frame.columns)\n",
    "        returnlist.append(frame.reindex(columns=common_columns))\n",
    "    return returnlist\n",
    "\n",
    "def readcsvs(csv_loc_list:list):\n",
    "    individual_dataframes = []\n",
    "    for i in range(len(csv_loc_list)):\n",
    "        individual_dataframes.append(readcsv_modified(csv_loc_list[i])) #time series\n",
    "\n",
    "    #Here: Go through the loop once again, start trimming. compare everything to element at 0, trim with it so it stays as the leanest version.\n",
    "\n",
    "    removed_nans = []\n",
    "    for frame in individual_dataframes:\n",
    "        removed_nans.append(removeNaNs(frame))\n",
    "\n",
    "    # initial_df = removed_nans[0]\n",
    "    # removed_unique_cols = []\n",
    "    # for frame in removed_nans[1:]:\n",
    "    #     reduced_frames = removeUniqueColumns(initial_df, frame)\n",
    "    #     initial_df = reduced_frames[0]\n",
    "    #     removed_unique_cols.append(reduced_frames[1])\n",
    "    \n",
    "    # removed_unique_cols.append(initial_df)\n",
    "    removed_unique_cols = removeUniqueColumns2(removed_nans)\n",
    "    concated = pd.concat(removed_unique_cols, keys=[f'csv {i}' for i in range(1, len(removed_unique_cols)+1)])\n",
    "\n",
    "    #concated.index = pd.MultiIndex.from_tuples([(idx, date) for idx, date in zip(concated.index.get_level_values(0), concated.index.get_level_values(1))], names=['files','times'])\n",
    "    concated2 = concated.reindex(index=pd.MultiIndex.from_tuples([(idx, date) for idx, date in zip(concated.index.get_level_values(0), concated.index.get_level_values(1))], names=['files','times']))\n",
    "    #print(concated2)\n",
    "    #return removed_unique_cols\n",
    "    return concated2\n",
    "\n",
    "def add_to_frame(csv_loc:str, frame:pd.DataFrame, name:str):\n",
    "    #call readcsv to get a finished dataframe with the things in it. \n",
    "    #get an index of potentially different length that has to be cleaned.\n",
    "    current_highest_num = frame.index.get_level_values('instances').max() \n",
    "    newframe = readcsv(csv_loc, name, current_highest_num)\n",
    "\n",
    "    return concat_dfs(frame, newframe)\n",
    "    csv = pd.read_csv(csv_loc)\n",
    "    new_vals = csv.drop(labels=\"identifier\", axis=1).to_numpy().transpose()\n",
    "    #vals = np.append(frame.values, new_vals)\n",
    "    vals = np.array(frame.values)\n",
    "    merged = merge_with_new(vals, new_vals)\n",
    "    added = np.concatenate([vals, new_vals],axis=0)\n",
    "    print(added, added.shape)\n",
    "    #Get a copy of the date index, expand it with another name\n",
    "    index = frame.index\n",
    "    name_index = index.levels[0].to_list()\n",
    "    name_index.append(name)\n",
    "    timepoints = index.get_level_values('timepoints')\n",
    "    new_index = pd.MultiIndex.from_product([name_index, timepoints], names=['instances','timepoints'])\n",
    "    \n",
    "\n",
    "    df = pd.DataFrame(vals,  index=new_index, columns=frame.columns)\n",
    "    return df\n",
    "\n",
    "# catalog = readcsv(\"../Test_datasets/catalog.csv\", \"catalog\")\n",
    "# updated = add_to_frame(\"../Test_datasets/even_load.csv\", catalog, \"even_load\")\n",
    "# updated = add_to_frame(\"../Test_datasets/catalog2.csv\",updated, \"catalog\")\n",
    "# updated\n",
    "#simple = readcsv(\"../Test_datasets/simple1.csv\", \"simple1\")\n",
    "#simple2 = readcsv(\"../Test_datasets/simple2.csv\", \"simple1\")\n",
    "# simple\n",
    "#Do I really have to synchronize the dates? What happens if I just let them be as they are. Does the algorithm care? It would be relative and not absolute anyway. Fuck all this actually. Just concat that shit?\n",
    "#266 * 601\n",
    "#Could not broadcast from 133,601.\n",
    "file_list = [\"F:/Master/Kubernetes/sockshop/microservices-demo/analysis/Test_datasets/catalog.csv\",\n",
    "             \"F:/Master/Kubernetes/sockshop/microservices-demo/analysis/Test_datasets/catalog2.csv\",\n",
    "             \"F:/Master/Kubernetes/sockshop/microservices-demo/analysis/Test_datasets/even_load.csv\"]\n",
    "complete_df = readcsvs(file_list)\n",
    "\n",
    "from get_all_metrics_with_tags import get_all_metrics_with_tags\n",
    "better_file_list = get_all_metrics_with_tags(r\"F:\\Master\\Kubernetes\\sockshop\\microservices-demo\\query\\automated\\generated_csvs\")\n",
    "y = [\"catalog\",\n",
    "     \"catalog\",\n",
    "     \"even_load\"]\n",
    "#print(complete_df)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sktime.transformations.panel.rocket import Rocket\n",
    "scaler = StandardScaler()\n",
    "fitted = scaler.fit_transform(complete_df)\n",
    "rocket = Rocket()\n",
    "rocket.fit(fitted,y)\n",
    "new_df = pd.DataFrame(data=fitted, index = complete_df.index, columns=complete_df.columns)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3e90e1a1473f170485a9d276321f87f2208c7adda2047c45136ed578a7f25d18"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
