{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nordb\\AppData\\Local\\Temp\\ipykernel_14852\\2314209265.py:12: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  timestamps = pd.Int64Index(timestamps, dtype=np.int64)\n",
      "C:\\Users\\nordb\\AppData\\Local\\Temp\\ipykernel_14852\\2314209265.py:12: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  timestamps = pd.Int64Index(timestamps, dtype=np.int64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([1, 2, 3, 4, 5, 6, 7, 8], dtype='int64')\n",
      "MultiIndex([('simple1', 1),\n",
      "            ('simple1', 2),\n",
      "            ('simple1', 3),\n",
      "            ('simple1', 4),\n",
      "            ('simple1', 5),\n",
      "            ('simple1', 6),\n",
      "            ('simple1', 7),\n",
      "            ('simple1', 8)],\n",
      "           names=['instances', 'timepoints'])\n",
      "Int64Index([1, 2, 3, 4, 5, 6, 7, 8], dtype='int64')\n",
      "MultiIndex([('simple1', 1),\n",
      "            ('simple1', 2),\n",
      "            ('simple1', 3),\n",
      "            ('simple1', 4),\n",
      "            ('simple1', 5),\n",
      "            ('simple1', 6),\n",
      "            ('simple1', 7),\n",
      "            ('simple1', 8)],\n",
      "           names=['instances', 'timepoints'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>first</th>\n",
       "      <th>second</th>\n",
       "      <th>third</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instances</th>\n",
       "      <th>timepoints</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">simple1</th>\n",
       "      <th>1</th>\n",
       "      <td>312</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>345</td>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>355</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>355</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>356</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>354</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>355</td>\n",
       "      <td>1</td>\n",
       "      <td>654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>356</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      first  second  third\n",
       "instances timepoints                      \n",
       "simple1   1             312       0     45\n",
       "          2             345       0     87\n",
       "          3             355       0     23\n",
       "          4             355       0     67\n",
       "          5             356       1     12\n",
       "          6             354       1      3\n",
       "          7             355       1    654\n",
       "          8             356       2      4"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sktime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def readcsv(csv_loc:str, name:str):\n",
    "    csv = pd.read_csv(csv_loc)\n",
    "\n",
    "    # print(csv.to_string())\n",
    "    metrics = csv[\"identifier\"].to_list()\n",
    "    timestamps = csv.columns[1:].to_flat_index()\n",
    "    timestamps = timestamps.to_numpy().tolist()\n",
    "    timestamps = pd.Int64Index(timestamps, dtype=np.int64)\n",
    "    print(timestamps)\n",
    "    index = pd.MultiIndex.from_product([[name], timestamps], names=['instances','timepoints'])\n",
    "    print(index)\n",
    "    vals = csv.drop(labels=\"identifier\",axis=1).to_numpy().transpose()\n",
    "    s = pd.DataFrame(vals, index=index, columns=metrics)\n",
    "    return s\n",
    "\n",
    "\n",
    "\n",
    "simple = readcsv(\"../Test_datasets/simple1.csv\", \"simple1\")\n",
    "simple2 = readcsv(\"../Test_datasets/simple2.csv\", \"simple1\")\n",
    "from sktime.transformations.panel.rocket import Rocket\n",
    "\n",
    "rocket = Rocket()\n",
    "rocket.fit(simple)\n",
    "rocket.fit(simple2)\n",
    "simple\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below is my some code I will use for formatting unix timestamps to datetimeIndex, not relevant  ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 10 13 0.1 9.0 75.0 0.2 8.0 1.0 0.22 7.0 0.5 0.3 6.0 24.0 0.3 5.0 7.0\n",
      " 0.3 4.0 5.0 0.4 3.0 23.0 0.5 3.0 56.0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instances</th>\n",
       "      <th>timepoints</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">increase</th>\n",
       "      <th>2023-01-18 12:32:47</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-18 12:32:52</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-18 12:32:57</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-18 12:33:02</th>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-18 12:33:07</th>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-18 12:33:12</th>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-18 12:33:17</th>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-18 12:33:22</th>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-18 12:33:27</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">decrease</th>\n",
       "      <th>2023-01-18 12:32:47</th>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-18 12:32:52</th>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-18 12:32:57</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-18 12:33:02</th>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-18 12:33:07</th>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-18 12:33:12</th>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-18 12:33:17</th>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-18 12:33:22</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-18 12:33:27</th>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">neither</th>\n",
       "      <th>2023-01-18 12:32:47</th>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-18 12:32:52</th>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-18 12:32:57</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-18 12:33:02</th>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-18 12:33:07</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-18 12:33:12</th>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-18 12:33:17</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-18 12:33:22</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-18 12:33:27</th>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  0\n",
       "instances timepoints               \n",
       "increase  2023-01-18 12:32:47     0\n",
       "          2023-01-18 12:32:52    10\n",
       "          2023-01-18 12:32:57    13\n",
       "          2023-01-18 12:33:02   0.1\n",
       "          2023-01-18 12:33:07   9.0\n",
       "          2023-01-18 12:33:12  75.0\n",
       "          2023-01-18 12:33:17   0.2\n",
       "          2023-01-18 12:33:22   8.0\n",
       "          2023-01-18 12:33:27   1.0\n",
       "decrease  2023-01-18 12:32:47  0.22\n",
       "          2023-01-18 12:32:52   7.0\n",
       "          2023-01-18 12:32:57   0.5\n",
       "          2023-01-18 12:33:02   0.3\n",
       "          2023-01-18 12:33:07   6.0\n",
       "          2023-01-18 12:33:12  24.0\n",
       "          2023-01-18 12:33:17   0.3\n",
       "          2023-01-18 12:33:22   5.0\n",
       "          2023-01-18 12:33:27   7.0\n",
       "neither   2023-01-18 12:32:47   0.3\n",
       "          2023-01-18 12:32:52   4.0\n",
       "          2023-01-18 12:32:57   5.0\n",
       "          2023-01-18 12:33:02   0.4\n",
       "          2023-01-18 12:33:07   3.0\n",
       "          2023-01-18 12:33:12  23.0\n",
       "          2023-01-18 12:33:17   0.5\n",
       "          2023-01-18 12:33:22   3.0\n",
       "          2023-01-18 12:33:27  56.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import sktime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def readcsv(csv_loc:str):\n",
    "    csv = pd.read_csv(csv_loc).transpose()\n",
    "    metrics = csv.loc[\"identifier\"].to_list()\n",
    "    timestamps = pd.DatetimeIndex(np.array(csv.index[1:].astype('int').tolist(), dtype='datetime64[s]'))\n",
    "    print(csv.values[1:].flatten())\n",
    "    vals = csv.values[1:].flatten()\n",
    "    index = pd.MultiIndex.from_product([metrics, timestamps], names=['instances','timepoints'])\n",
    "    s = pd.DataFrame(vals, index=index)\n",
    "    return s\n",
    "    # metrics = csv[\"identifier\"].to_list()\n",
    "    # timestamps = csv.columns[1:].to_flat_index()\n",
    "    # timestamps = timestamps.to_numpy().tolist()\n",
    "    # timestamps = pd.Int64Index(timestamps, dtype=np.int64)\n",
    "    \n",
    "    # index = pd.MultiIndex.from_product([metrics, timestamps], names=['instances','timepoints'])\n",
    "    # vals = csv.drop(labels=\"identifier\",axis=1).to_numpy().flatten()\n",
    "    # s = pd.DataFrame(vals, index=index)\n",
    "    # return s\n",
    "\n",
    "\n",
    "\n",
    "simple = readcsv(\"../DTW/testing.csv\")\n",
    "simple\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['F:/Master/Kubernetes/sockshop/microservices-demo/query/automated/generated_csvs_2/carts/rand 1678978299.0_663.csv', 'F:/Master/Kubernetes/sockshop/microservices-demo/query/automated/generated_csvs_2/carts/rand 1678981388.0_1546.csv', 'F:/Master/Kubernetes/sockshop/microservices-demo/query/automated/generated_csvs_2/carts/rand 1678984479.0_1202.csv', 'F:/Master/Kubernetes/sockshop/microservices-demo/query/automated/generated_csvs_2/carts/rand 1678987567.0_917.csv', 'F:/Master/Kubernetes/sockshop/microservices-demo/query/automated/generated_csvs_2/carts/rand 1678990654.0_642.csv', 'F:/Master/Kubernetes/sockshop/microservices-demo/query/automated/generated_csvs_2/carts/rand 1678993741.0_1403.csv', 'F:/Master/Kubernetes/sockshop/microservices-demo/query/automated/generated_csvs_2/catalog/rand 1678978299.0_996.csv', 'F:/Master/Kubernetes/sockshop/microservices-demo/query/automated/generated_csvs_2/catalog/rand 1678981388.0_1211.csv', 'F:/Master/Kubernetes/sockshop/microservices-demo/query/automated/generated_csvs_2/catalog/rand 1678984479.0_285.csv', 'F:/Master/Kubernetes/sockshop/microservices-demo/query/automated/generated_csvs_2/catalog/rand 1678987567.0_172.csv', 'F:/Master/Kubernetes/sockshop/microservices-demo/query/automated/generated_csvs_2/catalog/rand 1678990654.0_368.csv', 'F:/Master/Kubernetes/sockshop/microservices-demo/query/automated/generated_csvs_2/catalog/rand 1678993741.0_813.csv', 'F:/Master/Kubernetes/sockshop/microservices-demo/query/automated/generated_csvs_2/even_load/rand 1678978299.0_561.csv', 'F:/Master/Kubernetes/sockshop/microservices-demo/query/automated/generated_csvs_2/even_load/rand 1678981388.0_1064.csv', 'F:/Master/Kubernetes/sockshop/microservices-demo/query/automated/generated_csvs_2/even_load/rand 1678984479.0_1757.csv', 'F:/Master/Kubernetes/sockshop/microservices-demo/query/automated/generated_csvs_2/even_load/rand 1678987567.0_504.csv', 'F:/Master/Kubernetes/sockshop/microservices-demo/query/automated/generated_csvs_2/even_load/rand 1678990654.0_258.csv', 'F:/Master/Kubernetes/sockshop/microservices-demo/query/automated/generated_csvs_2/even_load/rand 1678993741.0_1499.csv', 'F:/Master/Kubernetes/sockshop/microservices-demo/query/automated/generated_csvs_2/even_load/rand 1678996829.0_1914.csv', 'F:/Master/Kubernetes/sockshop/microservices-demo/query/automated/generated_csvs_2/idle/rand 1678978299.0_624.csv', 'F:/Master/Kubernetes/sockshop/microservices-demo/query/automated/generated_csvs_2/idle/rand 1678981388.0_1876.csv', 'F:/Master/Kubernetes/sockshop/microservices-demo/query/automated/generated_csvs_2/idle/rand 1678984479.0_208.csv', 'F:/Master/Kubernetes/sockshop/microservices-demo/query/automated/generated_csvs_2/idle/rand 1678987567.0_428.csv', 'F:/Master/Kubernetes/sockshop/microservices-demo/query/automated/generated_csvs_2/idle/rand 1678990654.0_763.csv', 'F:/Master/Kubernetes/sockshop/microservices-demo/query/automated/generated_csvs_2/idle/rand 1678993741.0_1156.csv', 'F:/Master/Kubernetes/sockshop/microservices-demo/query/automated/generated_csvs_2/users/rand 1678978299.0_586.csv', 'F:/Master/Kubernetes/sockshop/microservices-demo/query/automated/generated_csvs_2/users/rand 1678981388.0_1779.csv', 'F:/Master/Kubernetes/sockshop/microservices-demo/query/automated/generated_csvs_2/users/rand 1678984479.0_507.csv', 'F:/Master/Kubernetes/sockshop/microservices-demo/query/automated/generated_csvs_2/users/rand 1678987567.0_1597.csv', 'F:/Master/Kubernetes/sockshop/microservices-demo/query/automated/generated_csvs_2/users/rand 1678990654.0_584.csv', 'F:/Master/Kubernetes/sockshop/microservices-demo/query/automated/generated_csvs_2/users/rand 1678993741.0_211.csv'] ['carts', 'carts', 'carts', 'carts', 'carts', 'carts', 'catalog', 'catalog', 'catalog', 'catalog', 'catalog', 'catalog', 'even_load', 'even_load', 'even_load', 'even_load', 'even_load', 'even_load', 'even_load', 'idle', 'idle', 'idle', 'idle', 'idle', 'idle', 'users', 'users', 'users', 'users', 'users', 'users']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>go_gc_duration_seconds&amp;catalogue:80&amp;catalogue&amp;0.25</th>\n",
       "      <th>go_gc_duration_seconds&amp;catalogue:80&amp;catalogue&amp;0.5</th>\n",
       "      <th>go_gc_duration_seconds&amp;payment:80&amp;payment&amp;0.25</th>\n",
       "      <th>go_gc_duration_seconds&amp;payment:80&amp;payment&amp;0.5</th>\n",
       "      <th>go_gc_duration_seconds&amp;payment:80&amp;payment&amp;0.75</th>\n",
       "      <th>go_gc_duration_seconds&amp;user:80&amp;user&amp;0.25</th>\n",
       "      <th>go_gc_duration_seconds&amp;user:80&amp;user&amp;0.5</th>\n",
       "      <th>go_gc_duration_seconds&amp;user:80&amp;user&amp;0.75</th>\n",
       "      <th>go_goroutines&amp;catalogue:80&amp;catalogue</th>\n",
       "      <th>go_goroutines&amp;payment:80&amp;payment</th>\n",
       "      <th>...</th>\n",
       "      <th>go_memstats_heap_sys_bytes&amp;user:80&amp;user</th>\n",
       "      <th>go_memstats_mspan_inuse_bytes&amp;catalogue:80&amp;catalogue</th>\n",
       "      <th>go_memstats_mspan_inuse_bytes&amp;payment:80&amp;payment</th>\n",
       "      <th>go_memstats_mspan_inuse_bytes&amp;user:80&amp;user</th>\n",
       "      <th>go_memstats_next_gc_bytes&amp;catalogue:80&amp;catalogue</th>\n",
       "      <th>go_memstats_next_gc_bytes&amp;user:80&amp;user</th>\n",
       "      <th>go_memstats_stack_inuse_bytes&amp;user:80&amp;user</th>\n",
       "      <th>go_memstats_stack_sys_bytes&amp;user:80&amp;user</th>\n",
       "      <th>jvm_threads_current&amp;carts:80&amp;cart</th>\n",
       "      <th>jvm_threads_daemon&amp;carts:80&amp;cart</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">csv 1</th>\n",
       "      <th>2023-03-16 14:40:39</th>\n",
       "      <td>0.000367</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>0.000445</td>\n",
       "      <td>0.000416</td>\n",
       "      <td>0.000512</td>\n",
       "      <td>0.000619</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>28934144.0</td>\n",
       "      <td>76480.0</td>\n",
       "      <td>44320.0</td>\n",
       "      <td>162880.0</td>\n",
       "      <td>4788124.0</td>\n",
       "      <td>7592942.0</td>\n",
       "      <td>3571712.0</td>\n",
       "      <td>3571712.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-16 14:40:44</th>\n",
       "      <td>0.000367</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>0.000445</td>\n",
       "      <td>0.000416</td>\n",
       "      <td>0.000512</td>\n",
       "      <td>0.000619</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>28934144.0</td>\n",
       "      <td>76480.0</td>\n",
       "      <td>44160.0</td>\n",
       "      <td>162400.0</td>\n",
       "      <td>4788124.0</td>\n",
       "      <td>7570067.0</td>\n",
       "      <td>3571712.0</td>\n",
       "      <td>3571712.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-16 14:40:49</th>\n",
       "      <td>0.000367</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>0.000445</td>\n",
       "      <td>0.000416</td>\n",
       "      <td>0.000512</td>\n",
       "      <td>0.000619</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>28934144.0</td>\n",
       "      <td>76640.0</td>\n",
       "      <td>44320.0</td>\n",
       "      <td>162560.0</td>\n",
       "      <td>4788124.0</td>\n",
       "      <td>7570067.0</td>\n",
       "      <td>3571712.0</td>\n",
       "      <td>3571712.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-16 14:40:54</th>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>0.000445</td>\n",
       "      <td>0.000416</td>\n",
       "      <td>0.000512</td>\n",
       "      <td>0.000619</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>28934144.0</td>\n",
       "      <td>76640.0</td>\n",
       "      <td>44800.0</td>\n",
       "      <td>162720.0</td>\n",
       "      <td>4516319.0</td>\n",
       "      <td>7570067.0</td>\n",
       "      <td>3571712.0</td>\n",
       "      <td>3571712.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-16 14:40:59</th>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>0.000445</td>\n",
       "      <td>0.000416</td>\n",
       "      <td>0.000512</td>\n",
       "      <td>0.000619</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>28934144.0</td>\n",
       "      <td>76640.0</td>\n",
       "      <td>44320.0</td>\n",
       "      <td>162880.0</td>\n",
       "      <td>4516319.0</td>\n",
       "      <td>7570067.0</td>\n",
       "      <td>3571712.0</td>\n",
       "      <td>3571712.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">csv 31</th>\n",
       "      <th>2023-03-16 19:08:41</th>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>0.000348</td>\n",
       "      <td>0.000369</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.000485</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>46989312.0</td>\n",
       "      <td>110400.0</td>\n",
       "      <td>44640.0</td>\n",
       "      <td>325760.0</td>\n",
       "      <td>5086518.0</td>\n",
       "      <td>17230134.0</td>\n",
       "      <td>6488064.0</td>\n",
       "      <td>6488064.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-16 19:08:46</th>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>0.000348</td>\n",
       "      <td>0.000369</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.000485</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>46989312.0</td>\n",
       "      <td>110560.0</td>\n",
       "      <td>44800.0</td>\n",
       "      <td>326080.0</td>\n",
       "      <td>5086518.0</td>\n",
       "      <td>17230134.0</td>\n",
       "      <td>6488064.0</td>\n",
       "      <td>6488064.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-16 19:08:51</th>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>0.000348</td>\n",
       "      <td>0.000369</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.000485</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>46989312.0</td>\n",
       "      <td>110240.0</td>\n",
       "      <td>44960.0</td>\n",
       "      <td>326880.0</td>\n",
       "      <td>5004022.0</td>\n",
       "      <td>17230134.0</td>\n",
       "      <td>6488064.0</td>\n",
       "      <td>6488064.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-16 19:08:56</th>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>0.000348</td>\n",
       "      <td>0.000369</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.000485</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>46989312.0</td>\n",
       "      <td>110400.0</td>\n",
       "      <td>45440.0</td>\n",
       "      <td>327040.0</td>\n",
       "      <td>5004022.0</td>\n",
       "      <td>17230134.0</td>\n",
       "      <td>6488064.0</td>\n",
       "      <td>6488064.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-16 19:09:01</th>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>0.000348</td>\n",
       "      <td>0.000369</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.000485</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>46989312.0</td>\n",
       "      <td>110560.0</td>\n",
       "      <td>44640.0</td>\n",
       "      <td>327840.0</td>\n",
       "      <td>4194304.0</td>\n",
       "      <td>17230134.0</td>\n",
       "      <td>6488064.0</td>\n",
       "      <td>6488064.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4123 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            go_gc_duration_seconds&catalogue:80&catalogue&0.25  \\\n",
       "csv 1  2023-03-16 14:40:39                                           0.000367    \n",
       "       2023-03-16 14:40:44                                           0.000367    \n",
       "       2023-03-16 14:40:49                                           0.000367    \n",
       "       2023-03-16 14:40:54                                           0.000366    \n",
       "       2023-03-16 14:40:59                                           0.000366    \n",
       "...                                                                       ...    \n",
       "csv 31 2023-03-16 19:08:41                                           0.000347    \n",
       "       2023-03-16 19:08:46                                           0.000347    \n",
       "       2023-03-16 19:08:51                                           0.000347    \n",
       "       2023-03-16 19:08:56                                           0.000347    \n",
       "       2023-03-16 19:09:01                                           0.000347    \n",
       "\n",
       "                            go_gc_duration_seconds&catalogue:80&catalogue&0.5  \\\n",
       "csv 1  2023-03-16 14:40:39                                           0.000444   \n",
       "       2023-03-16 14:40:44                                           0.000444   \n",
       "       2023-03-16 14:40:49                                           0.000444   \n",
       "       2023-03-16 14:40:54                                           0.000441   \n",
       "       2023-03-16 14:40:59                                           0.000441   \n",
       "...                                                                       ...   \n",
       "csv 31 2023-03-16 19:08:41                                           0.000366   \n",
       "       2023-03-16 19:08:46                                           0.000366   \n",
       "       2023-03-16 19:08:51                                           0.000366   \n",
       "       2023-03-16 19:08:56                                           0.000366   \n",
       "       2023-03-16 19:09:01                                           0.000366   \n",
       "\n",
       "                            go_gc_duration_seconds&payment:80&payment&0.25  \\\n",
       "csv 1  2023-03-16 14:40:39                                        0.000329   \n",
       "       2023-03-16 14:40:44                                        0.000328   \n",
       "       2023-03-16 14:40:49                                        0.000328   \n",
       "       2023-03-16 14:40:54                                        0.000328   \n",
       "       2023-03-16 14:40:59                                        0.000327   \n",
       "...                                                                    ...   \n",
       "csv 31 2023-03-16 19:08:41                                        0.000332   \n",
       "       2023-03-16 19:08:46                                        0.000332   \n",
       "       2023-03-16 19:08:51                                        0.000332   \n",
       "       2023-03-16 19:08:56                                        0.000332   \n",
       "       2023-03-16 19:09:01                                        0.000332   \n",
       "\n",
       "                            go_gc_duration_seconds&payment:80&payment&0.5  \\\n",
       "csv 1  2023-03-16 14:40:39                                       0.000362   \n",
       "       2023-03-16 14:40:44                                       0.000362   \n",
       "       2023-03-16 14:40:49                                       0.000362   \n",
       "       2023-03-16 14:40:54                                       0.000362   \n",
       "       2023-03-16 14:40:59                                       0.000360   \n",
       "...                                                                   ...   \n",
       "csv 31 2023-03-16 19:08:41                                       0.000348   \n",
       "       2023-03-16 19:08:46                                       0.000348   \n",
       "       2023-03-16 19:08:51                                       0.000348   \n",
       "       2023-03-16 19:08:56                                       0.000348   \n",
       "       2023-03-16 19:09:01                                       0.000348   \n",
       "\n",
       "                            go_gc_duration_seconds&payment:80&payment&0.75  \\\n",
       "csv 1  2023-03-16 14:40:39                                        0.000445   \n",
       "       2023-03-16 14:40:44                                        0.000445   \n",
       "       2023-03-16 14:40:49                                        0.000445   \n",
       "       2023-03-16 14:40:54                                        0.000445   \n",
       "       2023-03-16 14:40:59                                        0.000445   \n",
       "...                                                                    ...   \n",
       "csv 31 2023-03-16 19:08:41                                        0.000369   \n",
       "       2023-03-16 19:08:46                                        0.000369   \n",
       "       2023-03-16 19:08:51                                        0.000369   \n",
       "       2023-03-16 19:08:56                                        0.000369   \n",
       "       2023-03-16 19:09:01                                        0.000369   \n",
       "\n",
       "                            go_gc_duration_seconds&user:80&user&0.25  \\\n",
       "csv 1  2023-03-16 14:40:39                                  0.000416   \n",
       "       2023-03-16 14:40:44                                  0.000416   \n",
       "       2023-03-16 14:40:49                                  0.000416   \n",
       "       2023-03-16 14:40:54                                  0.000416   \n",
       "       2023-03-16 14:40:59                                  0.000416   \n",
       "...                                                              ...   \n",
       "csv 31 2023-03-16 19:08:41                                  0.000388   \n",
       "       2023-03-16 19:08:46                                  0.000388   \n",
       "       2023-03-16 19:08:51                                  0.000388   \n",
       "       2023-03-16 19:08:56                                  0.000388   \n",
       "       2023-03-16 19:09:01                                  0.000388   \n",
       "\n",
       "                            go_gc_duration_seconds&user:80&user&0.5  \\\n",
       "csv 1  2023-03-16 14:40:39                                 0.000512   \n",
       "       2023-03-16 14:40:44                                 0.000512   \n",
       "       2023-03-16 14:40:49                                 0.000512   \n",
       "       2023-03-16 14:40:54                                 0.000512   \n",
       "       2023-03-16 14:40:59                                 0.000512   \n",
       "...                                                             ...   \n",
       "csv 31 2023-03-16 19:08:41                                 0.000417   \n",
       "       2023-03-16 19:08:46                                 0.000417   \n",
       "       2023-03-16 19:08:51                                 0.000417   \n",
       "       2023-03-16 19:08:56                                 0.000417   \n",
       "       2023-03-16 19:09:01                                 0.000417   \n",
       "\n",
       "                            go_gc_duration_seconds&user:80&user&0.75  \\\n",
       "csv 1  2023-03-16 14:40:39                                  0.000619   \n",
       "       2023-03-16 14:40:44                                  0.000619   \n",
       "       2023-03-16 14:40:49                                  0.000619   \n",
       "       2023-03-16 14:40:54                                  0.000619   \n",
       "       2023-03-16 14:40:59                                  0.000619   \n",
       "...                                                              ...   \n",
       "csv 31 2023-03-16 19:08:41                                  0.000485   \n",
       "       2023-03-16 19:08:46                                  0.000485   \n",
       "       2023-03-16 19:08:51                                  0.000485   \n",
       "       2023-03-16 19:08:56                                  0.000485   \n",
       "       2023-03-16 19:09:01                                  0.000485   \n",
       "\n",
       "                            go_goroutines&catalogue:80&catalogue  \\\n",
       "csv 1  2023-03-16 14:40:39                                  10.0   \n",
       "       2023-03-16 14:40:44                                  11.0   \n",
       "       2023-03-16 14:40:49                                  10.0   \n",
       "       2023-03-16 14:40:54                                  10.0   \n",
       "       2023-03-16 14:40:59                                  10.0   \n",
       "...                                                          ...   \n",
       "csv 31 2023-03-16 19:08:41                                  11.0   \n",
       "       2023-03-16 19:08:46                                  11.0   \n",
       "       2023-03-16 19:08:51                                  10.0   \n",
       "       2023-03-16 19:08:56                                  10.0   \n",
       "       2023-03-16 19:09:01                                  11.0   \n",
       "\n",
       "                            go_goroutines&payment:80&payment  ...  \\\n",
       "csv 1  2023-03-16 14:40:39                              11.0  ...   \n",
       "       2023-03-16 14:40:44                              11.0  ...   \n",
       "       2023-03-16 14:40:49                              11.0  ...   \n",
       "       2023-03-16 14:40:54                              11.0  ...   \n",
       "       2023-03-16 14:40:59                              12.0  ...   \n",
       "...                                                      ...  ...   \n",
       "csv 31 2023-03-16 19:08:41                              12.0  ...   \n",
       "       2023-03-16 19:08:46                              11.0  ...   \n",
       "       2023-03-16 19:08:51                              11.0  ...   \n",
       "       2023-03-16 19:08:56                              11.0  ...   \n",
       "       2023-03-16 19:09:01                              11.0  ...   \n",
       "\n",
       "                            go_memstats_heap_sys_bytes&user:80&user  \\\n",
       "csv 1  2023-03-16 14:40:39                               28934144.0   \n",
       "       2023-03-16 14:40:44                               28934144.0   \n",
       "       2023-03-16 14:40:49                               28934144.0   \n",
       "       2023-03-16 14:40:54                               28934144.0   \n",
       "       2023-03-16 14:40:59                               28934144.0   \n",
       "...                                                             ...   \n",
       "csv 31 2023-03-16 19:08:41                               46989312.0   \n",
       "       2023-03-16 19:08:46                               46989312.0   \n",
       "       2023-03-16 19:08:51                               46989312.0   \n",
       "       2023-03-16 19:08:56                               46989312.0   \n",
       "       2023-03-16 19:09:01                               46989312.0   \n",
       "\n",
       "                            go_memstats_mspan_inuse_bytes&catalogue:80&catalogue  \\\n",
       "csv 1  2023-03-16 14:40:39                                            76480.0      \n",
       "       2023-03-16 14:40:44                                            76480.0      \n",
       "       2023-03-16 14:40:49                                            76640.0      \n",
       "       2023-03-16 14:40:54                                            76640.0      \n",
       "       2023-03-16 14:40:59                                            76640.0      \n",
       "...                                                                       ...      \n",
       "csv 31 2023-03-16 19:08:41                                           110400.0      \n",
       "       2023-03-16 19:08:46                                           110560.0      \n",
       "       2023-03-16 19:08:51                                           110240.0      \n",
       "       2023-03-16 19:08:56                                           110400.0      \n",
       "       2023-03-16 19:09:01                                           110560.0      \n",
       "\n",
       "                            go_memstats_mspan_inuse_bytes&payment:80&payment  \\\n",
       "csv 1  2023-03-16 14:40:39                                           44320.0   \n",
       "       2023-03-16 14:40:44                                           44160.0   \n",
       "       2023-03-16 14:40:49                                           44320.0   \n",
       "       2023-03-16 14:40:54                                           44800.0   \n",
       "       2023-03-16 14:40:59                                           44320.0   \n",
       "...                                                                      ...   \n",
       "csv 31 2023-03-16 19:08:41                                           44640.0   \n",
       "       2023-03-16 19:08:46                                           44800.0   \n",
       "       2023-03-16 19:08:51                                           44960.0   \n",
       "       2023-03-16 19:08:56                                           45440.0   \n",
       "       2023-03-16 19:09:01                                           44640.0   \n",
       "\n",
       "                            go_memstats_mspan_inuse_bytes&user:80&user  \\\n",
       "csv 1  2023-03-16 14:40:39                                    162880.0   \n",
       "       2023-03-16 14:40:44                                    162400.0   \n",
       "       2023-03-16 14:40:49                                    162560.0   \n",
       "       2023-03-16 14:40:54                                    162720.0   \n",
       "       2023-03-16 14:40:59                                    162880.0   \n",
       "...                                                                ...   \n",
       "csv 31 2023-03-16 19:08:41                                    325760.0   \n",
       "       2023-03-16 19:08:46                                    326080.0   \n",
       "       2023-03-16 19:08:51                                    326880.0   \n",
       "       2023-03-16 19:08:56                                    327040.0   \n",
       "       2023-03-16 19:09:01                                    327840.0   \n",
       "\n",
       "                            go_memstats_next_gc_bytes&catalogue:80&catalogue  \\\n",
       "csv 1  2023-03-16 14:40:39                                         4788124.0   \n",
       "       2023-03-16 14:40:44                                         4788124.0   \n",
       "       2023-03-16 14:40:49                                         4788124.0   \n",
       "       2023-03-16 14:40:54                                         4516319.0   \n",
       "       2023-03-16 14:40:59                                         4516319.0   \n",
       "...                                                                      ...   \n",
       "csv 31 2023-03-16 19:08:41                                         5086518.0   \n",
       "       2023-03-16 19:08:46                                         5086518.0   \n",
       "       2023-03-16 19:08:51                                         5004022.0   \n",
       "       2023-03-16 19:08:56                                         5004022.0   \n",
       "       2023-03-16 19:09:01                                         4194304.0   \n",
       "\n",
       "                            go_memstats_next_gc_bytes&user:80&user  \\\n",
       "csv 1  2023-03-16 14:40:39                               7592942.0   \n",
       "       2023-03-16 14:40:44                               7570067.0   \n",
       "       2023-03-16 14:40:49                               7570067.0   \n",
       "       2023-03-16 14:40:54                               7570067.0   \n",
       "       2023-03-16 14:40:59                               7570067.0   \n",
       "...                                                            ...   \n",
       "csv 31 2023-03-16 19:08:41                              17230134.0   \n",
       "       2023-03-16 19:08:46                              17230134.0   \n",
       "       2023-03-16 19:08:51                              17230134.0   \n",
       "       2023-03-16 19:08:56                              17230134.0   \n",
       "       2023-03-16 19:09:01                              17230134.0   \n",
       "\n",
       "                            go_memstats_stack_inuse_bytes&user:80&user  \\\n",
       "csv 1  2023-03-16 14:40:39                                   3571712.0   \n",
       "       2023-03-16 14:40:44                                   3571712.0   \n",
       "       2023-03-16 14:40:49                                   3571712.0   \n",
       "       2023-03-16 14:40:54                                   3571712.0   \n",
       "       2023-03-16 14:40:59                                   3571712.0   \n",
       "...                                                                ...   \n",
       "csv 31 2023-03-16 19:08:41                                   6488064.0   \n",
       "       2023-03-16 19:08:46                                   6488064.0   \n",
       "       2023-03-16 19:08:51                                   6488064.0   \n",
       "       2023-03-16 19:08:56                                   6488064.0   \n",
       "       2023-03-16 19:09:01                                   6488064.0   \n",
       "\n",
       "                            go_memstats_stack_sys_bytes&user:80&user  \\\n",
       "csv 1  2023-03-16 14:40:39                                 3571712.0   \n",
       "       2023-03-16 14:40:44                                 3571712.0   \n",
       "       2023-03-16 14:40:49                                 3571712.0   \n",
       "       2023-03-16 14:40:54                                 3571712.0   \n",
       "       2023-03-16 14:40:59                                 3571712.0   \n",
       "...                                                              ...   \n",
       "csv 31 2023-03-16 19:08:41                                 6488064.0   \n",
       "       2023-03-16 19:08:46                                 6488064.0   \n",
       "       2023-03-16 19:08:51                                 6488064.0   \n",
       "       2023-03-16 19:08:56                                 6488064.0   \n",
       "       2023-03-16 19:09:01                                 6488064.0   \n",
       "\n",
       "                            jvm_threads_current&carts:80&cart  \\\n",
       "csv 1  2023-03-16 14:40:39                               25.0   \n",
       "       2023-03-16 14:40:44                               25.0   \n",
       "       2023-03-16 14:40:49                               25.0   \n",
       "       2023-03-16 14:40:54                               25.0   \n",
       "       2023-03-16 14:40:59                               25.0   \n",
       "...                                                       ...   \n",
       "csv 31 2023-03-16 19:08:41                               25.0   \n",
       "       2023-03-16 19:08:46                               25.0   \n",
       "       2023-03-16 19:08:51                               25.0   \n",
       "       2023-03-16 19:08:56                               25.0   \n",
       "       2023-03-16 19:09:01                               25.0   \n",
       "\n",
       "                            jvm_threads_daemon&carts:80&cart  \n",
       "csv 1  2023-03-16 14:40:39                              23.0  \n",
       "       2023-03-16 14:40:44                              23.0  \n",
       "       2023-03-16 14:40:49                              23.0  \n",
       "       2023-03-16 14:40:54                              23.0  \n",
       "       2023-03-16 14:40:59                              23.0  \n",
       "...                                                      ...  \n",
       "csv 31 2023-03-16 19:08:41                              23.0  \n",
       "       2023-03-16 19:08:46                              23.0  \n",
       "       2023-03-16 19:08:51                              23.0  \n",
       "       2023-03-16 19:08:56                              23.0  \n",
       "       2023-03-16 19:09:01                              23.0  \n",
       "\n",
       "[4123 rows x 37 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def merge_with_new(existing_vals:pd.DataFrame, new_vals:pd.DataFrame) -> np.ndarray :\n",
    "    common_columns = existing_vals.columns.intersection(new_vals.columns)\n",
    "    reduced_existing = existing_vals.reindex(columns=common_columns)\n",
    "    reduced_new = new_vals.reindex(columns=common_columns)\n",
    "    timestamps = reduced_existing.index.get_level_values(1)\n",
    "\n",
    "    row = existing_vals.iloc[(slice(None),0)]\n",
    "    print(row.index)\n",
    "    \n",
    "    newnames = reduced_new.index.get_level_values(0).drop_duplicates()\n",
    "    oldnames = reduced_existing.index.get_level_values(0).drop_duplicates()\n",
    "    combined_names = oldnames.union(newnames)\n",
    "\n",
    "    tuples = [(i,j) for i in combined_names for j in timestamps]\n",
    "    index = pd.MultiIndex.from_tuples(tuples)\n",
    "\n",
    "    reduced_combined = pd.concat([reduced_existing,reduced_new],axis=0)\n",
    "    reduced_combined = reduced_combined.set_index(index)\n",
    "    #remove any columns that exists in one but not the other\n",
    "    return reduced_combined\n",
    "\n",
    "def make_datetime_index(timestamps:list) -> pd.DatetimeIndex:\n",
    "    beginning = timestamps[0]\n",
    "    end = timestamps[-1]\n",
    "    beginning, end = pd.to_datetime((beginning,end), unit=\"s\")\n",
    "    index = pd.date_range(start=beginning, end=end, periods=len(timestamps))\n",
    "    return index\n",
    "\n",
    "def concat_dfs(old:pd.DataFrame, new:pd.DataFrame) -> pd.DataFrame:\n",
    "    unioned = old.index.union(new.index)\n",
    "    concated = pd.concat([old.reindex(unioned), new.reindex(unioned)])\n",
    "    return concated\n",
    "\n",
    "def readcsv(csv_loc:str, num:int):\n",
    "    csv = pd.read_csv(csv_loc)\n",
    "    metrics = csv[\"identifier\"].to_list()\n",
    "    timestamps = csv.columns[1:].to_flat_index()\n",
    "    timestamps = timestamps.to_numpy().tolist()\n",
    "    timestamps = make_datetime_index(timestamps)\n",
    "    index = pd.MultiIndex.from_product([[num], timestamps], names=['instances','timepoints'])\n",
    "    vals = csv.drop(labels=\"identifier\",axis=1).to_numpy().transpose()\n",
    "    s = pd.DataFrame(vals, index=index, columns=metrics)\n",
    "    return s\n",
    "\n",
    "def readcsv_modified(csv_loc:str):\n",
    "    csv = pd.read_csv(csv_loc)\n",
    "    metrics = csv[\"identifier\"].to_list()\n",
    "    timestamps = csv.columns[1:].to_flat_index()\n",
    "    timestamps = timestamps.to_numpy().tolist()\n",
    "    timestamps = make_datetime_index(timestamps)\n",
    "   # index = pd.MultiIndex.from_product([[num], timestamps], names=['instances','timepoints'])\n",
    "    vals = csv.drop(labels=\"identifier\",axis=1).to_numpy().transpose()\n",
    "    s = pd.DataFrame(vals, index=timestamps, columns=metrics)\n",
    "    return s\n",
    "\n",
    "def removeNaNs(df:pd.DataFrame) -> pd.DataFrame:\n",
    "    for col in df.columns:\n",
    "        if df[col].isna().any():\n",
    "            df = df.drop(col, axis=1)\n",
    "    return df\n",
    "\n",
    "def removeUniqueColumns(first:pd.DataFrame, second:pd.DataFrame) -> tuple:\n",
    "    common_columns = first.columns.intersection(second.columns)\n",
    "    reduced_old = first.reindex(columns=common_columns)\n",
    "    reduced_new = second.reindex(columns=common_columns)\n",
    "    return reduced_old, reduced_new\n",
    "\n",
    "def removeUniqueColumns2(frames:list) -> list:\n",
    "    template:pd.DataFrame = frames[0]\n",
    "    #Round 1: Reduces the first frame to be the smallest size to match with everyone\n",
    "    for frame in frames[1:]:\n",
    "        common_columns = template.columns.intersection(frame.columns)\n",
    "        template = template.reindex(columns=common_columns)\n",
    "    returnlist = [template]\n",
    "    #Round 2: Reduces all the other ones to the same minimum\n",
    "    for frame in frames[1:]:\n",
    "        common_columns = template.columns.intersection(frame.columns)\n",
    "        returnlist.append(frame.reindex(columns=common_columns))\n",
    "    return returnlist\n",
    "\n",
    "def remove_monotonically_increasing_rows(df_list:list):\n",
    "    x:pd.DataFrame\n",
    "    returnlist = []\n",
    "    for x in df_list:\n",
    "        dropme = []\n",
    "        for column in x.columns:\n",
    "            if x[column].is_monotonic_increasing or x[column].is_monotonic_decreasing:\n",
    "                dropme.append(column)\n",
    "        returnlist.append(x.drop(dropme,axis=1))\n",
    "    return returnlist\n",
    "\n",
    "def remove_monotonic_rows(df_list:list):\n",
    "    x:pd.DataFrame\n",
    "    returnlist = []\n",
    "    for x in df_list:\n",
    "        row_count = x.apply(pd.Series.nunique, axis=1)\n",
    "        returnlist.append(x[row_count > 1])\n",
    "    return returnlist\n",
    "\n",
    "\n",
    "def readcsvs(csv_loc_list:list):\n",
    "    individual_dataframes = []\n",
    "    for i in range(len(csv_loc_list)):\n",
    "        individual_dataframes.append(readcsv_modified(csv_loc_list[i])) #time series\n",
    "\n",
    "    #monotonic rows create issues in the data by adding noise that doesn't help\n",
    "    #Instead of all this, maybe just do dtw\n",
    "    #individual_dataframes = remove_monotonic_rows(individual_dataframes)\n",
    "    individual_dataframes = remove_monotonically_increasing_rows(individual_dataframes)\n",
    "    #Here: Go through the loop once again, start trimming. compare everything to element at 0, trim with it so it stays as the leanest version.\n",
    "\n",
    "    removed_nans = []\n",
    "    for frame in individual_dataframes:\n",
    "        removed_nans.append(removeNaNs(frame))\n",
    "\n",
    "    # initial_df = removed_nans[0]\n",
    "    # removed_unique_cols = []\n",
    "    # for frame in removed_nans[1:]:\n",
    "    #     reduced_frames = removeUniqueColumns(initial_df, frame)\n",
    "    #     initial_df = reduced_frames[0]\n",
    "    #     removed_unique_cols.append(reduced_frames[1])\n",
    "    \n",
    "    # removed_unique_cols.append(initial_df)\n",
    "    removed_unique_cols = removeUniqueColumns2(removed_nans)\n",
    "    concated = pd.concat(removed_unique_cols, keys=[f'csv {i}' for i in range(1, len(removed_unique_cols)+1)])\n",
    "\n",
    "    #concated.index = pd.MultiIndex.from_tuples([(idx, date) for idx, date in zip(concated.index.get_level_values(0), concated.index.get_level_values(1))], names=['files','times'])\n",
    "    #concated2 = concated.reindex(index=pd.MultiIndex.from_tuples([(idx, date) for idx, date in zip(concated.index.get_level_values(0), concated.index.get_level_values(1))], names=['files','times']))\n",
    "    #print(concated2)\n",
    "    #return removed_unique_cols\n",
    "    return concated\n",
    "\n",
    "\n",
    "def present_data(list_of_ndarrays:list) -> pd.DataFrame:\n",
    "    return pd.concat(list_of_ndarrays, keys=[f'csv {i}' for i in range(1, len(list_of_ndarrays)+1)])\n",
    "\n",
    "def add_to_frame(csv_loc:str, frame:pd.DataFrame, name:str):\n",
    "    #call readcsv to get a finished dataframe with the things in it. \n",
    "    #get an index of potentially different length that has to be cleaned.\n",
    "    current_highest_num = frame.index.get_level_values('instances').max() \n",
    "    newframe = readcsv(csv_loc, name, current_highest_num)\n",
    "\n",
    "    return concat_dfs(frame, newframe)\n",
    "    csv = pd.read_csv(csv_loc)\n",
    "    new_vals = csv.drop(labels=\"identifier\", axis=1).to_numpy().transpose()\n",
    "    #vals = np.append(frame.values, new_vals)\n",
    "    vals = np.array(frame.values)\n",
    "    merged = merge_with_new(vals, new_vals)\n",
    "    added = np.concatenate([vals, new_vals],axis=0)\n",
    "    print(added, added.shape)\n",
    "    #Get a copy of the date index, expand it with another name\n",
    "    index = frame.index\n",
    "    name_index = index.levels[0].to_list()\n",
    "    name_index.append(name)\n",
    "    timepoints = index.get_level_values('timepoints')\n",
    "    new_index = pd.MultiIndex.from_product([name_index, timepoints], names=['instances','timepoints'])\n",
    "    \n",
    "\n",
    "    df = pd.DataFrame(vals,  index=new_index, columns=frame.columns)\n",
    "    return df\n",
    "\n",
    "def make_list_of_vals(input:pd.DataFrame) -> list:\n",
    "    newlist = []\n",
    "    x:str\n",
    "    for x in input.index.get_level_values(0).unique():\n",
    "        newlist.append(input.loc[x].values)\n",
    "    return newlist\n",
    "\n",
    "def make_list_of_dfs(input:pd.DataFrame) -> list:\n",
    "    newlist = []\n",
    "    x:str\n",
    "    for x in input.index.get_level_values(0).unique():\n",
    "        newlist.append(input.loc[x])\n",
    "    return newlist\n",
    "\n",
    "def get_dimensions(input:list):\n",
    "    return np.array(input).shape\n",
    "\n",
    "\n",
    "from get_all_metrics_with_tags import get_all_metrics_with_tags\n",
    "better_file_list, y = get_all_metrics_with_tags(r\"F:\\Master\\Kubernetes\\sockshop\\microservices-demo\\query\\automated\\generated_csvs_2\")\n",
    "print(better_file_list, y)\n",
    "#print(complete_df)\n",
    "\n",
    "#fitted = scaler.fit_transform(complete_df)\n",
    "#rocket.fit(fitted,y)\n",
    "#new_df = pd.DataFrame(data=fitted, index = complete_df.index, columns=complete_df.columns)\n",
    "X = readcsvs(better_file_list)\n",
    "X\n",
    "\n",
    "#Next: reshape and re-reshape the matrices to allow or scaling. Why did it work before?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2608695652173913\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#######PREPROCESSING#############\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sktime.transformations.panel.rocket import Rocket\n",
    "from sktime.transformations.panel.rocket import MiniRocketMultivariate\n",
    "from sklearn.preprocessing import normalize\n",
    "from sktime.datatypes import check_raise\n",
    "from sktime.classification.kernel_based import RocketClassifier\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "from sktime.datatypes import convert_to\n",
    "\n",
    "\n",
    "converted = convert_to(X, to_type=['pd-multiindex','numpyflat'])\n",
    "\n",
    "vals_list = make_list_of_vals(X)\n",
    "df_list = make_list_of_dfs(X)\n",
    "\n",
    "rocket = Rocket()\n",
    "minirocket = MiniRocketMultivariate()\n",
    "rocketclassifier = RocketClassifier()\n",
    "ridgeclassifier = RidgeClassifierCV(alphas=np.logspace(-3, 3, 10))\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "\n",
    "def standard_scale(train, test):\n",
    "    scaler = StandardScaler()\n",
    "    train_scaled = []\n",
    "    test_scaled = []\n",
    "\n",
    "    for df_train in train:\n",
    "        train_scaled.append(pd.DataFrame(data = scaler.fit_transform(df_train.values), index=df_train.index))\n",
    "    \n",
    "    for df_test in test:\n",
    "        test_scaled.append(pd.DataFrame(data=scaler.fit_transform(df_test.values), index=df_test.index))\n",
    "\n",
    "    return train_scaled, test_scaled\n",
    "\n",
    "def minmax_scale(train, test):\n",
    "    minmax = MinMaxScaler()\n",
    "\n",
    "#scaled = scaler.fit_transform(X)\n",
    "X_train,X_test, y_train, y_test = train_test_split(df_list, y)\n",
    "rocketclassifier.fit(X_train, np.array(y_train))\n",
    "print(rocketclassifier.score(X_train,y_train)) \n",
    "\n",
    "\n",
    "minirocket.fit(X_train)\n",
    "X_train_transform = minirocket.transform(X_train)\n",
    "X_train_scaled_transform = scaler.fit_transform(X_train_transform)\n",
    "\n",
    "classifier = RidgeClassifierCV(alphas=np.logspace(-3,3,10))\n",
    "classifier.fit(X_train_scaled_transform, y_train)\n",
    "X_test_transform = minirocket.transform(X_test)\n",
    "X_test_scaled_transform = scaler.transform(X_test_transform)\n",
    "classifier.score(X_test_scaled_transform, y_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3e90e1a1473f170485a9d276321f87f2208c7adda2047c45136ed578a7f25d18"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
