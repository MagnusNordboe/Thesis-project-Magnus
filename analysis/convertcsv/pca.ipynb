{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from import_dfs import readcsvs\n",
    "from sktime.datatypes import convert_to\n",
    "from sktime.datatypes import MTYPE_REGISTER\n",
    "from sktime.datatypes import SCITYPE_REGISTER\n",
    "\n",
    "from get_all_metrics_with_tags import get_all_metrics_with_tags\n",
    "better_file_list, y = get_all_metrics_with_tags(r\"F:\\Master\\Kubernetes\\sockshop\\microservices-demo\\query\\automated\\generated_csvs_4\")\n",
    "\n",
    "df = readcsvs(better_file_list, remove_monotonic_increasing=True)\n",
    "converted = convert_to(df, 'df-list')\n",
    "df\n",
    "#Get a large enough data set, and eventually every single metric is cleansed from somewhere. When then removing unique columns, you end up with zero, having cleaned away all of you data.\n",
    "#Potential solves: Perform PCA on each dataset before doing any cleaning at all. This boils down the amount of metrics measured to an approximation of the most important ones.\n",
    "#Other potential solve: Do not remove unique columns, and instead use only datatypes and classifiers that can handle unique features. This sounds risky as it will still need equal features to compare somewhere.\n",
    "#Other potential solve: Changing the metrics that sometimes monotonically increase, to instead work on a differential level. Check if there is a built in method for that perhaps?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating DF. Metod: PCA\n",
    "df = readcsvs(better_file_list, remove_monotonic_increasing=True, PCA=True)\n",
    "converted = convert_to(df, 'df-list')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(df)\n",
    "pca = PCA(n_components=25)\n",
    "principal_comoponents = pca.fit_transform(scaled_data)\n",
    "newdf = pd.DataFrame(principal_comoponents, index=df.index)\n",
    "newdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rocket,  removed monotonic, removed monotonically increasing, standardscaled\n",
    "\n",
    "from sktime.classification.kernel_based import RocketClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train,X_test, y_train, y_test = train_test_split(convert_to(df, 'df-list'), y)\n",
    "\n",
    "rocket = RocketClassifier()\n",
    "fitted = rocket.fit(X_train, np.array(y_train))\n",
    "print(fitted.predict(X_test))\n",
    "print(fitted.score(X_test, np.array(y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rocket with RobustScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "robscale = RobustScaler()\n",
    "X_train_multiindex = convert_to(X_train, 'pd-multiindex')\n",
    "robscale.fit(X_train_multiindex)\n",
    "X_train_robust = robscale.transform(X_train_multiindex)\n",
    "X_test_robust = robscale.transform(convert_to(X_test, 'pd-multiindex'))\n",
    "\n",
    "classifier = RidgeClassifierCV(alphas=np.logspace(-3,3,10))\n",
    "print(X_train_multiindex.shape)\n",
    "X_train_robust = np.reshape(X_train_robust, X_train_multiindex.shape)\n",
    "classifier.fit(X_train_robust, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
