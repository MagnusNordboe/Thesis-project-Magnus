{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sktime\n",
    "import seaborn as snsc\n",
    "import matplotlib.pyplot as plt\n",
    "from convertcsv.import_preprocess_v4 import readcsvs\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sktime.transformations.panel.rocket import Rocket\n",
    "from sktime.transformations.panel.rocket import MiniRocketMultivariate\n",
    "from sktime.classification.kernel_based import RocketClassifier\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "from sklearn.impute import KNNImputer\n",
    "from convertcsv.get_all_metrics_with_tags import get_all_metrics_with_tags\n",
    "from visualization import graphs\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sktime.datatypes import convert_to\n",
    "from sktime.datatypes import MTYPE_REGISTER\n",
    "from collections import Counter\n",
    "from sktime.classification.interval_based import TimeSeriesForestClassifier\n",
    "from sktime.classification.compose import ClassifierPipeline\n",
    "from storage.retrieve_csv import retrieve_csv\n",
    "from storage.store_csv import store_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = retrieve_csv(\"scaled_and_trimmed\")\n",
    "variances = pd.read_json(\"./storage/sorted_variance.json\",orient=\"index\")\n",
    "variances.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Try_Classifiers:\n",
    "    #Goal: run the various classifiers. Do Normalization/standarization outside of this function.\n",
    "    #Then in here, only classifiers should be needed. All classifiers implement fit and fit_transform as well as fit_predict.\n",
    "    #If there are multiple classes that passed in, make the pipeline fit_transform -> fit_predict. Otherwise just fit_predict.\n",
    "    \n",
    "    def __init__(self, X_train:pd.DataFrame, y_train=None, X_test=None, y_test=None):\n",
    "        self.formats = [self.format_dflist, self.format_multiindex, self.format_multiindex_manual, self.format_multiindex_dflist]\n",
    "        self.X_train_cols = X_train.columns\n",
    "        self.X_train_index = X_train.index\n",
    "        self.X_train = X_train\n",
    "        if y_train is not None:\n",
    "            self.y_train = y_train\n",
    "        if X_test is not None:\n",
    "            self.X_test = X_test\n",
    "        if y_test is not None:\n",
    "            self.y_test = y_test\n",
    "\n",
    "\n",
    "    def _try_function_with_formats(self, class_function, X, y=None):\n",
    "        latestexception:Exception\n",
    "        try:\n",
    "            result = None\n",
    "            if y is not None:\n",
    "                result = class_function(X, y)\n",
    "            else:\n",
    "                result = class_function(X)\n",
    "            return result, True\n",
    "        except Exception as e:    \n",
    "            latestexception = e      \n",
    "            for fmt in self.formats:\n",
    "                try:\n",
    "                    formatted_X = fmt(X)\n",
    "                    result = None\n",
    "                    if y is not None: \n",
    "                        result = class_function(formatted_X, y)\n",
    "                    else:\n",
    "                        result = class_function(formatted_X)\n",
    "                    return result, True\n",
    "                except Exception as e:\n",
    "                    latestexception = e\n",
    "                    continue\n",
    "            print(latestexception)\n",
    "            return None, False\n",
    "    \n",
    "    def format_dflist(self, input):\n",
    "        return convert_to(input, to_type=\"df-list\")\n",
    "\n",
    "    def format_multiindex(self, input):\n",
    "        return convert_to(input, to_type=\"pd-multiindex\")\n",
    "\n",
    "    def format_multiindex_manual(self, input):\n",
    "        return pd.DataFrame(input, columns=self.X_train_cols, index=self.X_train_index)\n",
    "    \n",
    "    def format_multiindex_dflist(self, input):\n",
    "        return convert_to(pd.DataFrame(input, columns=self.X_train_cols, index=self.X_train_index), to_type=\"df-list\")\n",
    "\n",
    "    def run_fit_predict_single(self, class_to_use):\n",
    "        \n",
    "        result, completed = self._try_function_with_formats(class_to_use.fit,self.X_train, self.y_train)\n",
    "        \n",
    "        if not completed:\n",
    "            return Exception(\"Couldn't fit\")\n",
    "\n",
    "        if hasattr(class_to_use, 'score'):\n",
    "            score, completed = self._try_function_with_formats(class_to_use.predict, self.X_test, self.y_test)\n",
    "        else:\n",
    "            prediction, completed = self._try_function_with_formats(class_to_use.predict, self.X_test)\n",
    "            score = np.mean(prediction == self.y_test)\n",
    "            \n",
    "        \n",
    "        if not completed:\n",
    "            return Exception(\"Something went wrong\")\n",
    "\n",
    "#It runs the local fit function before sending it to the loop that catches exceptions\n",
    "#The way to fix this is make sure that the fit and predict functions happen inside the loop. It has to handle multiple inputs or just one\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_variance(df:pd.DataFrame) ->pd.Series:\n",
    "    #The coefficient of variation\n",
    "    cv = df.std() / df.mean()\n",
    "    return cv.round(10).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_by_variance(df:pd.DataFrame, amount:int):\n",
    "    variances:pd.Series = calculate_variance(df)\n",
    "    selection = variances.iloc[0:amount]\n",
    "    return selection.index\n",
    "best_features = select_by_variance(X, 3)\n",
    "X = X[best_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_list = [group.reset_index(level=0,drop=True) for _, group in X.groupby(level=0)]\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_list, y)\n",
    "\n",
    "# Convert each dataframe to have a multiindex\n",
    "X_train = [df.assign(outer=i).set_index(['outer', df.index]) for i, df in enumerate(X_train)]\n",
    "X_train = pd.concat(X_train)\n",
    "X_test = [df.assign(outer=i).set_index(['outer', df.index]) for i, df in enumerate(X_test)]\n",
    "X_test = pd.concat(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In this one, let's run with only the top 3. Run through many predictors.\n",
    "# Importing necessary libraries\n",
    "import numpy as np\n",
    "from sktime.classification.interval_based import TimeSeriesForestClassifier\n",
    "from sktime.classification.compose import ColumnEnsembleClassifier\n",
    "from sktime.classification.dictionary_based import BOSSEnsemble\n",
    "from sktime.transformations.panel.compose import ColumnConcatenator\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Initiate sktime classifiers\n",
    "tsf = TimeSeriesForestClassifier()\n",
    "boss = BOSSEnsemble()\n",
    "\n",
    "# A multivariate time series can be thought of as a table of univariate time series.\n",
    "# sktime's ColumnEnsembleClassifier treats each column (univariate time series) as a separate classification task and then aggregates predictions.\n",
    "# Here we demonstrate it with TSF, but you can replace it with other sktime classifiers.\n",
    "column_ens = ColumnEnsembleClassifier(estimators=[\n",
    "    (\"TSF0\", TimeSeriesForestClassifier(), [0]),\n",
    "    (\"TSF1\", TimeSeriesForestClassifier(), [1])\n",
    "    # ... you can add more columns as necessary\n",
    "])\n",
    "\n",
    "# For sklearn classifiers, you'd typically need to transform the time series data into a tabular format.\n",
    "# Here's an example using RandomForestClassifier from sklearn with ColumnConcatenator from sktime:\n",
    "concatenator = ColumnConcatenator()\n",
    "sklearn_classifier = make_pipeline(concatenator, RandomForestClassifier())\n",
    "\n",
    "# List of all classifiers\n",
    "classifiers = [tsf, boss,  column_ens, sklearn_classifier]\n",
    "\n",
    "# You can now loop through `classifiers` to train and evaluate them.\n",
    "looper = Try_Classifiers(X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No valid mtype could be identified for object of type <class 'pandas.core.frame.DataFrame'>. Errors returned are as follows, in format [mtype]: [error message] \n",
      "df-list: obj must be list of pd.DataFrame, found <class 'pandas.core.frame.DataFrame'>\n",
      "numpy3D: obj must be a numpy.ndarray, found <class 'pandas.core.frame.DataFrame'>\n",
      "pd-multiindex: <class 'pandas.core.indexes.multi.MultiIndex'> is not supported for obj, use one of (<class 'pandas.core.indexes.range.RangeIndex'>, <class 'pandas.core.indexes.period.PeriodIndex'>, <class 'pandas.core.indexes.datetimes.DatetimeIndex'>) or integer index instead.\n",
      "nested_univ: obj All columns must be object, found <class 'pandas.core.frame.DataFrame'>\n",
      "dask_panel: obj must be a dask DataFrame, found <class 'pandas.core.frame.DataFrame'>\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "looper._try_function_with_formats(tsf.fit_predict, X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
