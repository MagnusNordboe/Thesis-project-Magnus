Automatically generated by Mendeley Desktop 1.19.8
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@misc{Kiraly,
author = {Kiraly, Franz},
title = {{Sktime}},
url = {https://www.sktime.net/en/stable/},
urldate = {2023-11-15}
}
@article{Heinrich2017,
abstract = {Microservices complement approaches like DevOps and continuous delivery in terms of software architecture. Along with this architectural style, several important deployment technologies, such as container-based virtualization and container orchestration solutions, have emerged. These technologies allow to efficiently exploit cloud platforms, providing a high degree of scalability, availability, and portability for microservices. Despite the obvious importance of a sufficient level of performance, there is still a lack of performance engineering approaches explicitly taking into account the particularities of microservices. In this paper, we argue why new solutions to performance engineering for microservices are needed. Furthermore, we identify open issues and outline possible re- search directions with regard to performance-Aware testing, monitoring, and modeling of microservices.},
author = {Heinrich, Robert and {Van Hoorn}, Andr{\'{e}} and Knoche, Holger and Li, Fei and Lwakatare, Lucy Ellen and Pahl, Claus and Schulte, Stefan and Wettinger, Johannes},
doi = {10.1145/3053600.3053653},
file = {:home/magnus/.var/app/com.elsevier.MendeleyDesktop/data/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Heinrich et al. - 2017 - Performance engineering for microservices Research challenges {\&} directions.pdf:pdf},
isbn = {9781450348997},
journal = {ICPE 2017 - Companion of the 2017 ACM/SPEC International Conference on Performance Engineering},
month = {apr},
pages = {223--226},
publisher = {Association for Computing Machinery, Inc},
title = {{Performance engineering for microservices: Research challenges {\&} directions}},
url = {http://dx.doi.org/10.1145/3053600.3053653},
year = {2017}
}
@misc{DOT,
author = {DOT},
booktitle = {Department of transportation},
pages = {1--10},
title = {{Microsoft Word - Final2-28.doc | Enhanced Reader}},
urldate = {2023-07-14},
year = {2004}
}
@misc{Docker,
author = {Docker},
title = {{Runtime options with Memory, CPUs, and GPUs | Docker Docs}},
url = {https://docs.docker.com/config/containers/resource{\_}constraints/},
urldate = {2023-11-15}
}
@misc{Traefik,
author = {Traefik},
title = {{traefik/traefik: The Cloud Native Application Proxy}},
url = {https://github.com/traefik/traefik{\#}supported-backends},
urldate = {2023-11-14}
}
@misc{Locustio,
author = {Locustio},
title = {{locustio/locust: Write scalable load tests in plain Python}},
url = {https://github.com/locustio/locust},
urldate = {2023-03-27}
}
@article{Bogatinovski,
abstract = {Artificial Intelligence for IT Operations (AIOps) combines big data and machine learning to replace a broad range of IT Operations tasks including reliability and performance monitoring of services. By exploiting observability data, AIOps enable detection of faults and issues of services. The focus of this work is on detecting anomalies based on distributed tracing records that contain detailed information of the services of the distributed system. Timely and accurately detecting trace anomalies is very challenging due to the large number of underlying microservices and the complex call relationships between them. We addresses the problem anomaly detection from distributed traces with a novel self-supervised method and a new learning task formulation. The method is able to have high performance even in large traces and capture complex interactions between the services. The evaluation shows that the approach achieves high accuracy and solid performance in the experimental testbed.},
author = {Bogatinovski, Jasmin and Nedelkoski, Sasho and Cardoso, Jorge and Kao, Odej},
doi = {10.1109/UCC48980.2020.00054},
file = {::},
isbn = {9780738123943},
journal = {Proceedings - 2020 IEEE/ACM 13th International Conference on Utility and Cloud Computing, UCC 2020},
keywords = {Anomaly detection,Distributed systems,Distributed traces,Self-supervised learning},
pages = {342--347},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Self-supervised anomaly detection from distributed traces}},
year = {2020}
}
@article{Du2018,
abstract = {With emerging container technologies, such as Docker, microservices-based applications can be developed and deployed in cloud environment much agiler. The dependability of these microservices becomes a major concern of application providers. Anomalous behaviors which may lead to unexpected failures can be detected with anomaly detection techniques. In this paper, an anomaly detection system (ADS) is designed to detect and diagnose the anomalies in microservices by monitoring and analyzing real-time performance data of them. The proposed ADS consists of a monitoring module that collects the performance data of containers, a data processing module based on machine learning models and a fault injection module integrated for training these models. The fault injection module is also used to assess the anomaly detection and diagnosis performance of our ADS. Clearwater, an open source virtual IP Multimedia Subsystem, is used for the validation of our ADS and experimental results show that the proposed ADS works well.},
author = {Du, Qingfeng and Xie, Tiandi and He, Yu},
doi = {10.1007/978-3-030-05063-4_42},
file = {::},
isbn = {9783030050627},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Anomaly detection,Machine learning,Microservices,Performance monitoring},
pages = {560--572},
title = {{Anomaly detection and diagnosis for container-based microservices with performance monitoring}},
volume = {11337 LNCS},
year = {2018}
}
@misc{Devops-amazon,
author = {Amazon},
title = {{What is DevOps? - DevOps Models Explained - Amazon Web Services (AWS)}},
url = {https://aws.amazon.com/devops/what-is-devops/},
urldate = {2023-07-17}
}
@misc{Scikit-learn-imputation,
abstract = {Overview of imputation techniques in sklearn},
author = {Scikit-learn},
title = {{6.4. Imputation of missing values â€” scikit-learn 1.2.2 documentation}},
url = {https://scikit-learn.org/stable/modules/impute.html},
urldate = {2023-04-13}
}
@book{Raymond2003,
abstract = {The Art of UNIX Programming poses the belief that understanding the unwritten UNIX engineering tradition and mastering its design patterns will help programmers of all stripes to become better programmers. This book attempts to capture the engineering wisdom and design philosophy of the UNIX, Linux, and Open Source software development community as it has evolved over the past three decades, and as it is applied today by the most experienced programmers. Eric Raymond offers the next generation of "hackers" the unique opportunity to learn the connection between UNIX philosophy and practice through careful case studies of the very best UNIX/Linux programs.},
author = {Raymond, E.S.},
booktitle = {System},
isbn = {0131429019},
pages = {560},
title = {{The art of Unix programming}},
url = {http://portal.acm.org/citation.cfm?id=829549},
year = {2003}
}
@inproceedings{Grzesik2023,
author = {Grzesik, Andzej and Ptak, Wojtek},
booktitle = {Avoiding mistakes with events},
month = {aug},
publisher = {JavaZone},
title = {{JavaZone 2023 presentation: Avoiding mistakes with events, one event at a time - by Andrzej Grzesik, Wojtek Ptak}},
url = {https://2023.javazone.no/program/1306f8e9-af1b-4e2c-9ba3-7c4771b6aba1},
year = {2023}
}
@article{Guyon,
abstract = {Variable and feature selection have become the focus of much research in areas of application for which datasets with tens or hundreds of thousands of variables are available. These areas include text processing of internet documents, gene expression array analysis, and combinatorial chemistry. The objective of variable selection is threefold: improving the prediction performance of the pre-dictors, providing faster and more cost-effective predictors, and providing a better understanding of the underlying process that generated the data. The contributions of this special issue cover a wide range of aspects of such problems: providing a better definition of the objective function, feature construction, feature ranking, multivariate feature selection, efficient search methods, and feature validity assessment methods.},
author = {Guyon, Isabelle and De, Andre@tuebingen Mpg},
file = {::},
journal = {Journal of Machine Learning Research},
keywords = {QSAR,Variable selection,bioinformatics,clustering,computational biology,feature selection,filters,gene expression,genomics,information retrieval,information theory,microarray,model selection,pattern discov-ery,proteomics,space dimensionality reduction,statistical testing,support vector machines,text classification,wrappers},
pages = {1157--1182},
title = {{An Introduction to Variable and Feature Selection Andr{\'{e}} Elisseeff}},
volume = {3},
year = {2003}
}
@article{Gouigoux2017,
abstract = {MGDIS SA is a software editing company that underwent a major strategic and technical change during the past three years, investing 17 300 man. Days rewriting its core business software from monolithic architecture to a Web Oriented Architecture using microservices. The paper presents technical lessons learned during and from this migration by addressing three crucial questions for a successful context-adapted migration towards a Web Oriented Architecture: how to determine (i) the most suitable granularity of micro-services, (ii) the most appropriate deployment and (iii) the most efficient orchestration?},
author = {Gouigoux, Jean Philippe and Tamzalit, Dalila},
doi = {10.1109/ICSAW.2017.35},
isbn = {9781509047932},
journal = {Proceedings - 2017 IEEE International Conference on Software Architecture Workshops, ICSAW 2017: Side Track Proceedings},
keywords = {Microservices,Migration,Web Oriented Architecture},
pages = {62--65},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{From monolith to microservices: Lessons learned on an industrial migration to a web oriented architecture}},
year = {2017}
}
@article{Pasos,
abstract = {Time Series Classification (TSC) involves building predictive models for a discrete target variable from ordered, real valued, attributes. Over recent years, a new set of TSC algorithms have been developed which have made significant improvement over the previous state of the art. The main focus has been on univariate TSC, i.e. the problem where each case has a single series and a class label. In reality, it is more common to encounter multivariate TSC (MTSC) problems where the time series for a single case has multiple dimensions. Despite this, much less consideration has been given to MTSC than the univariate case. The UCR archive has provided a valuable resource for univariate TSC, and the lack of a standard set of test problems may explain why there has been less focus on MTSC. The UEA archive of 30 MTSC problems released in 2018 has made comparison of algorithms easier. We review recently proposed bespoke MTSC algorithms based on deep learning, shapelets and bag of words approaches. If an algorithm cannot naturally handle multivariate data, the simplest approach to adapt a univariate classifier to MTSC is to ensemble it over the multivariate dimensions. We compare the bespoke algorithms to these dimension independent approaches on the 26 of the 30 MTSC archive problems where the data are all of equal length. We demonstrate that four classifiers are significantly more accurate than the benchmark dynamic time warping algorithm and that one of these recently proposed classifiers, ROCKET, achieves significant improvement on the archive datasets in at least an order of magnitude less time than the other three.},
author = {{Pasos Ruiz}, Alejandro and Flynn, Michael and Large, James and Middlehurst, {\textperiodcentered} Matthew and Bagnall, {\textperiodcentered} Anthony},
doi = {10.1007/s10618-020-00727-3},
file = {:home/magnus/.var/app/com.elsevier.MendeleyDesktop/data/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pasos Ruiz et al. - 2021 - The great multivariate time series classification bake off a review and experimental evaluation of recent alg.pdf:pdf},
journal = {Data Mining and Knowledge Discovery},
keywords = {Evaluating classifiers,Multivariate time series,Time series classification,UEA archive},
pages = {401--449},
title = {{The great multivariate time series classification bake off: a review and experimental evaluation of recent algorithmic advances}},
url = {https://doi.org/10.1007/s10618-020-00727-3},
volume = {35},
year = {2021}
}
@inproceedings{Sergeev2022,
abstract = {At the moment, Docker technology is becoming more prevalent in the Windows environment. The pertinent topic in this regard is how Docker containers running on the Windows operating system would behave in the event of a resource deficit. The article discusses circumstances in which there is insufficient processor or RAM to service all running containers. It is proposed to employ stress and volume testing to investigate the stability and reliability of Docker containers. The purpose of stress testing is to determine how the system behaves when the load on the application is greatly increased in comparison to what was initially expected. By delivering enormous amounts of data for processing, volume testing is accomplished. To assess container performance during stress testing, a Prometheus-based technology stack is used. Docker containers running in a Windows system have been shown to operate predictably under extreme load conditions. As the processor load increases, the performance of the containerized program drops proportionately to the decrease in processor time allocated. When there is insufficient RAM to run all containers, Docker uses virtual memory to dynamically distribute memory amongst containers. If a container's execution is halted due to a lack of available RAM on the system, the container's execution is terminated. Other containers continue to function normally.},
author = {Sergeev, A. and Rezedinova, E. and Khakhina, A.},
booktitle = {Journal of Physics: Conference Series},
doi = {10.1088/1742-6596/2339/1/012010},
file = {:home/magnus/.var/app/com.elsevier.MendeleyDesktop/data/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sergeev, Rezedinova, Khakhina - 2022 - Stress testing of Docker containers running on a Windows operating system.pdf:pdf},
issn = {17426596},
number = {1},
publisher = {Institute of Physics},
title = {{Stress testing of Docker containers running on a Windows operating system}},
volume = {2339},
year = {2022}
}
@misc{springboot,
author = {Springboot},
booktitle = {GitHub},
title = {{spring-petclinic/spring-petclinic-microservices: Distributed version of Spring Petclinic built with Spring Cloud}},
url = {https://github.com/spring-petclinic/spring-petclinic-microservices},
urldate = {2023-10-24},
year = {2013}
}
@article{Gropp2011,
abstract = {The performance of parallel scientific applications depends on many factors which are determined by the execution environment and the parallel application. Especially on large parallel systems, it is too expensive to explore the solution space with series of experiments. Deriving analytical models for applications and platforms allow estimating and extrapolating their execution performance, bottlenecks, and the potential impact of optimization options. We propose to use such "performance modeling" techniques beginning from the application design process throughout the whole software development cycle and also during the lifetime of supercomputer systems. Such models help to guide supercomputer system design and re-engineering efforts to adopt applications to changing platforms and allow users to estimate costs to solve a particular problem. Models can often be built with the help of well-known performance profiling tools. We discuss how we successfully used modeling throughout the proposal, initial testing, and beginning deployment phase of the Blue Waters supercomputer system. Copyright 2011 ACM.},
author = {Hoefler, Torsten and Gropp, William and Snir, Marc and Kramer, William},
doi = {10.1145/2063348.2063356},
file = {:home/magnus/.var/app/com.elsevier.MendeleyDesktop/data/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hoefler et al. - 2011 - Performance modeling for systematic performance tuning.pdf:pdf},
isbn = {9781450311397},
journal = {State of the Practice Reports, SC'11},
publisher = {IEEE},
title = {{Performance modeling for systematic performance tuning}},
year = {2011}
}
@article{Zhou2021a,
abstract = {Storage services in data centers continuously make decisions, such as for cache admission, prefetching, and block allocation. These decisions are typically driven by heuristics based on statistical properties like temporal locality or common file sizes. The quality of decisions can be improved through application-level information such as the database operation a request belongs to. While such features can be exploited through application hints (e.g., explicit prefetches), this process requires manual work and is thus only viable for the most tuned workloads. In this work, we show how to leverage application-level information automatically, by building on distributed traces that are already available in warehouse-scale computers. As these traces are used for diagnostics and accounting, they contain information about requests, including those to storage services. However, this information is mostly unstructured (e.g., arbitrary text) and thus difficult to use. We demonstrate how to do so automatically using machine learning, by applying ideas from natural language processing. We show that different storage-related decisions can be learned from distributed traces, using models ranging from simple clustering techniques to neural networks. Instead of designing specific models for different storage-related tasks, we show that the same models can be used as building blocks for different tasks. Our models improve prediction accuracy by 11-33{\%} over non-ML baselines, which translates to significantly improving the hit rate of a caching task, as well as improvements to an SSD/HDD tiering task, on production data center storage traces.},
author = {Zhou, Giulio and Maas, Martin},
file = {::},
title = {{LEARNING ON DISTRIBUTED TRACES FOR DATA CENTER STORAGE SYSTEMS}},
year = {2021}
}
@misc{DgtlInfra,
author = {Infra, Dgtl},
title = {{Top 10 Cloud Service Providers Globally in 2023 - Dgtl Infra}},
url = {https://dgtlinfra.com/top-10-cloud-service-providers-2022/},
urldate = {2023-06-28}
}
@misc{Fowler2014,
author = {Fowler, Martin},
title = {{Microservices}},
url = {https://martinfowler.com/articles/microservices.html},
urldate = {2022-01-31},
year = {2014}
}
@article{Scalability,
author = {Weinstock, Charles B and Goodenough, John B},
file = {::},
journal = {U.S. Ministry of defence},
title = {{On System Scalability}},
url = {http://www.sei.cmu.edu/publications/pubweb.html},
year = {2006}
}
@incollection{Goodfellow2016,
author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
booktitle = {Deep Learning},
publisher = {MIT Press},
title = {{Autoencoders}},
url = {https://www.deeplearningbook.org/contents/autoencoders.html},
year = {2016}
}
@article{Samaras2009,
author = {Samaras, George},
doi = {10.1007/978-1-4899-7993-3_713-2},
file = {:home/magnus/.var/app/com.elsevier.MendeleyDesktop/data/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Samaras - 2009 - Two-Phase Commit.pdf:pdf},
title = {{Two-Phase Commit}},
url = {https://www.researchgate.net/publication/275155037},
year = {2009}
}
@misc{Richter,
author = {Richter, Felix},
booktitle = {Statista},
title = {{Cloud providers market share}},
url = {https://www.statista.com/chart/18819/worldwide-market-share-of-leading-cloud-infrastructure-service-providers/},
year = {2023}
}
@misc{pullrequest,
author = {Nordb{\o}, Magnus},
title = {{Locust pull request}},
url = {https://github.com/locustio/locust/pull/2248},
urldate = {2023-10-31},
year = {2023}
}
@article{Waskom2021,
author = {Waskom, Micheal L.},
doi = {10.21105/joss.03021},
journal = {Journal of Open Source Software},
title = {seaborn: statistical data visualization},
url = {https://doi.org/10.21105/joss.03021},
volume = {6},
year = {2021}
}
@misc{Nyberg,
author = {Nyberg, Simon},
title = {{siimon/prom-client: Prometheus client for node.js}},
url = {https://github.com/siimon/prom-client},
urldate = {2023-11-14}
}
@misc{McConnell2013,
author = {McConnell, Steve},
booktitle = {IEEE Software},
title = {{"Managing technical debt (slides)" in Workshop On Managing technical debtt (part of ICSE 2013)}},
year = {2013}
}
@misc{Weaveworks,
author = {Weaveworks},
title = {{Microservices Demo: Sock Shop}},
url = {https://microservices-demo.github.io/},
urldate = {2023-06-30}
}
@techreport{Michelson,
author = {Michelson, Brenda M and Seybold, Patricia},
file = {:home/magnus/.var/app/com.elsevier.MendeleyDesktop/data/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Michelson, Seybold - 2011 - Event-Driven Architecture Overview.pdf:pdf},
title = {{Event-Driven Architecture Overview}},
volume = {2},
year = {2011}
}
@article{Gan2019,
abstract = {Cloud services have recently started undergoing a major shift from monolithic applications, to graphs of hundreds of loosely-coupled microservices. Microservices fundamentally change a lot of assumptions current cloud systems are designed with, and present both opportunities and challenges when optimizing for quality of service (QoS) and utilization. In this paper we explore the implications microservices have across the cloud system stack. We first present Death- StarBench, a novel, open-source benchmark suite built with microservices that is representative of large end-to-end services, modular and extensible. DeathStarBench includes a social network, a media service, an e-commerce site, a banking system, and IoT applications for coordination control of UAV swarms. We then use DeathStarBench to study the architectural characteristics of microservices, their implications in networking and operating systems, their challenges with respect to cluster management, and their trade-offs in terms of application design and programming frameworks. Finally, we explore the tail at scale effects of microservices in real deployments with hundreds of users, and highlight the increased pressure they put on performance predictability.},
author = {Gan, Yu and Zhang, Yanqi and Cheng, Dailun and Shetty, Ankitha and Rathi, Priyal and Katarki, Nayan and Bruno, Ariana and Hu, Justin and Ritchken, Brian and Jackson, Brendon and Hu, Kelvin and Pancholi, Meghna and He, Yuan and Clancy, Brett and Colen, Chris and Wen, Fukang and Leung, Catherine and Wang, Siyuan and Zaruvinsky, Leon and Espinosa, Mateo and Lin, Rick and Liu, Zhongling and Padilla, Jake and Delimitrou, Christina},
doi = {10.1145/3297858.3304013},
file = {::},
isbn = {9781450362405},
journal = {International Conference on Architectural Support for Programming Languages and Operating Systems - ASPLOS},
keywords = {QoS,acceleration,cloud computing,cluster management,datacenters,fpga,microservices,serverless},
pages = {3--18},
title = {{An Open-Source Benchmark Suite for Microservices and Their Hardware-Software Implications for Cloud {\&} Edge Systems}},
year = {2019}
}
@article{Quevedo2007,
abstract = {The selection of a subset of input variables is often based on the previous construction of a ranking to order the variables according to a given criterion of relevancy. The objective is then to linearize the search, estimating the quality of subsets containing the topmost ranked variables. An algorithm devised to rank input variables according to their usefulness in the context of a learning task is presented. This algorithm is the result of a combination of simple and classical techniques, like correlation and orthogonalization, which allow the construction of a fast algorithm that also deals explicitly with redundancy. Additionally, the proposed ranker is endowed with a simple polynomial expansion of the input variables to cope with nonlinear problems. The comparison with some state-of-the-art rankers showed that this combination of simple components is able to yield high-quality rankings of input variables. The experimental validation is made on a wide range of artificial data sets and the quality of the rankings is assessed using a ROC-inspired setting, to avoid biased estimations due to any particular learning algorithm.},
author = {Quevedo, Jos{\'{e}} R and Bahamonde, Antonio and Luaces, Oscar},
doi = {10.1016/j.csda.2007.02.003},
file = {::},
journal = {Computational Statistics {\&} Data Analysis},
keywords = {Dimensionality reduction,Variable ranking},
pages = {578--595},
title = {{A simple and efficient method for variable ranking according to their usefulness for learning}},
url = {www.elsevier.com/locate/csda},
volume = {52},
year = {2007}
}
@misc{ITS,
abstract = {An application in which the user interface, business rules, and data access code is combined into a single executable program and deployed on one platform. A monolithic application operates independently from other applications, performing every step of the process needed to complete the entire business function. It does not share any logic or data across system or organizational boundaries. Databases are designed for access by single application systems within a single agency, not for access by multiple application systems in multiple agencies simultaneously.},
author = {ITS},
title = {{Glossary}},
url = {https://web.archive.org/web/20070902151937/http://www.its.state.nc.us/Information/Glossary/Glossm.asp},
urldate = {2023-03-27},
year = {2001}
}
@misc{USAToday,
author = {Schmidt, Julie},
booktitle = {USA Today},
title = {{USATODAY.com - Comair to replace old system that failed}},
url = {https://web.archive.org/web/20210126095521/https://usatoday30.usatoday.com/money/biztravel/2004-12-28-comair-usat{\_}x.htm},
urldate = {2023-07-04},
year = {2004}
}
@article{Devops-definition,
abstract = {Context: DevOps, the combination of Development and Operations, is a new way of thinking in the software engineering domain that recently received much attention. Given that DevOps is a new term and novel concept recently introduced, no common understanding of what it entails has been achieved yet. Consequently, definitions of DevOps often only represent a part that is relevant to the concept. Objective:This study aims to characterize DevOps by exploring central components of DevOps definitions reported in the literature, specifying practices explicitly proposed for DevOps and investigating the similarities and differences between DevOps and other existing methods in software engineering. Method: A systematic mapping study was conducted that used six electronic databases: IEEE, ACM, Inspec, Scopus, Wiley Online Library and Web of Science. Result: 44 studies have been selected that report a definition of DevOps, 15 studies explicitly stating DevOps practices, and 15 studies stating how DevOps is related to other existing methods. Papers in some cases stated a combination of a definition, practices, and relations to other methods, the total number of primary studies was 49. Conclusion: We proposed a definition for DevOps which may overcome inconsistencies over the various existing definitions of individual research studies. In addition, the practices explicitly proposed for DevOps have been presented as well as the relation to other software development methods.},
author = {Jabbari, Ramtin and Ali, Nauman Bin and Petersen, Kai and Tanveer, Binish},
doi = {10.1145/2962695.2962707},
isbn = {9781450341349},
journal = {ACM International Conference Proceeding Series},
keywords = {DevOps definition,DevOps practice,Software development method},
publisher = {Association for Computing Machinery},
title = {{What is DevOps? A systematic mapping study on definitions and practices}},
url = {https://dl.acm.org/doi/10.1145/2962695.2962707},
year = {2016}
}
@misc{Loukides,
author = {Loukides, Mike and Swoyer, Steve},
title = {{Microservices Adoption in 2020 â€“ O'Reilly}},
url = {https://www.oreilly.com/radar/microservices-adoption-in-2020/},
urldate = {2023-03-27}
}
@article{Curtis,
author = {Curtis, Bill},
file = {::},
keywords = {cyber resilience,measurement,software resilience,standards},
title = {{How Do You Measure Software Resilience?}},
url = {www.it-cisq.org}
}
@article{Nedelkoski2019,
abstract = {Artificial Intelligence for IT Operations (AIOps) combines big data and machine learning to replace a broad range of IT Operations tasks including availability, performance, and monitoring of services. By exploiting log, tracing, metric, and network data, AIOps enable detection of faults and issues of services. The focus of this work is on detecting anomalies based on distributed tracing records that contain detailed information for the availability and the response time of the services. In large-scale distributed systems, where a service is deployed on heterogeneous hardware and has multiple scenarios of normal operation, it becomes challenging to detect such anomalous cases. We address the problem by proposing unsupervised, response time anomaly detection based on deep learning data modeling techniques; unsupervised dynamic error threshold approach; tolerance module for false positive reduction; and descriptive classification of the anomalies. The evaluation shows that the approach achieves high accuracy and solid performance in both, experimental testbed and large-scale production cloud.},
author = {Nedelkoski, Sasho and Cardoso, Jorge and Kao, Odej},
doi = {10.1109/CCGRID.2019.00038},
isbn = {9781728109121},
journal = {Proceedings - 19th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing, CCGrid 2019},
keywords = {AIOps,Anomaly detection,Autoencoders,CNNs,Distributed tracing,GRUs,RNNs,Service reliability,Time series},
pages = {241--250},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Anomaly detection and classification using distributed tracing and deep learning}},
year = {2019}
}
@techreport{Baeza-Yates,
abstract = {Big data nowadays is a fashionable topic, independently of what people mean when they use this term. The challenges include how to capture, transfer, store, clean, analyze, filter, search, share, and visualize such data. But being big is just a matter of volume, although there is no clear agreement in the size threshold where big starts. Indeed, it is easy to capture large amounts of data using a brute force approach. So the real goal should not be big data but to ask ourselves, for a given problem, what is the right data and how much of it is needed.1 For some problems this would imply big data, but for the majority of the problems much less data is necessary. In this position paper we explore the trade-offs involved and the main problems that come with big data: scalability, redundancy, bias, noise, spam, and privacy.},
author = {Herold, Benjamin},
booktitle = {Education Week},
file = {:home/magnus/.var/app/com.elsevier.MendeleyDesktop/data/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Baeza-Yates - Unknown - Big Data or Right Data.pdf:pdf},
isbn = {16130073 (ISSN)},
issn = {16130073},
keywords = {Bias,Noise,Privacy,Redundancy,Scalability,Spam,Sparsity},
number = {17},
pages = {4},
title = {{Big Data or Big Brother?}},
url = {http://sourceforge.net/projects/supersensetag/.},
volume = {35},
year = {2016}
}
@misc{Nordboe2023,
author = {Nordboe, Magnus},
booktitle = {Zenodo},
title = {{Prometheus stress testing data from the microservices-demo "sockshop" application}},
url = {https://zenodo.org/records/10107954?token=eyJhbGciOiJIUzUxMiJ9.eyJpZCI6IjEyZTJhZDI3LTk5ZTMtNDkyNy1iMWQyLThiNWJiN2RjOWQ1NyIsImRhdGEiOnt9LCJyYW5kb20iOiI1NGUxMWI0NGYyNzYwNWYxOTA1M2ZkODBmNjNkNjk4MCJ9.IdwfvH0D7pc9QZnVk0t8cz7CK49XJV75hW8OFUfFQ3dBdfyvGfT2dV0TEDr},
urldate = {2023-11-12},
year = {2023}
}
