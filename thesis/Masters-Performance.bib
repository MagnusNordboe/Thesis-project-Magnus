Automatically generated by Mendeley Desktop 1.19.8
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Heinrich2017,
abstract = {Microservices complement approaches like DevOps and continuous delivery in terms of software architecture. Along with this architectural style, several important deployment technologies, such as container-based virtualization and container orchestration solutions, have emerged. These technologies allow to efficiently exploit cloud platforms, providing a high degree of scalability, availability, and portability for microservices. Despite the obvious importance of a sufficient level of performance, there is still a lack of performance engineering approaches explicitly taking into account the particularities of microservices. In this paper, we argue why new solutions to performance engineering for microservices are needed. Furthermore, we identify open issues and outline possible re- search directions with regard to performance-Aware testing, monitoring, and modeling of microservices.},
author = {Heinrich, Robert and {Van Hoorn}, Andr{\'{e}} and Knoche, Holger and Li, Fei and Lwakatare, Lucy Ellen and Pahl, Claus and Schulte, Stefan and Wettinger, Johannes},
doi = {10.1145/3053600.3053653},
file = {:home/magnus/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Heinrich et al. - 2017 - Performance engineering for microservices Research challenges {\&} directions.pdf:pdf},
isbn = {9781450348997},
journal = {ICPE 2017 - Companion of the 2017 ACM/SPEC International Conference on Performance Engineering},
month = {apr},
pages = {223--226},
publisher = {Association for Computing Machinery, Inc},
title = {{Performance engineering for microservices: Research challenges {\&} directions}},
url = {http://dx.doi.org/10.1145/3053600.3053653},
year = {2017}
}
@misc{Loukides,
author = {Loukides, Mike and Swoyer, Steve},
title = {{Microservices Adoption in 2020 â€“ O'Reilly}},
url = {https://www.oreilly.com/radar/microservices-adoption-in-2020/},
urldate = {2023-03-27}
}
@article{Du2018,
abstract = {With emerging container technologies, such as Docker, microservices-based applications can be developed and deployed in cloud environment much agiler. The dependability of these microservices becomes a major concern of application providers. Anomalous behaviors which may lead to unexpected failures can be detected with anomaly detection techniques. In this paper, an anomaly detection system (ADS) is designed to detect and diagnose the anomalies in microservices by monitoring and analyzing real-time performance data of them. The proposed ADS consists of a monitoring module that collects the performance data of containers, a data processing module based on machine learning models and a fault injection module integrated for training these models. The fault injection module is also used to assess the anomaly detection and diagnosis performance of our ADS. Clearwater, an open source virtual IP Multimedia Subsystem, is used for the validation of our ADS and experimental results show that the proposed ADS works well.},
author = {Du, Qingfeng and Xie, Tiandi and He, Yu},
doi = {10.1007/978-3-030-05063-4_42},
file = {:home/magnus/Documents/Master/Performance related articles/Anomaly detection with machine learning.pdf:pdf},
isbn = {9783030050627},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Anomaly detection,Machine learning,Microservices,Performance monitoring},
pages = {560--572},
title = {{Anomaly detection and diagnosis for container-based microservices with performance monitoring}},
volume = {11337 LNCS},
year = {2018}
}
@misc{Locustio,
author = {Locustio},
title = {{locustio/locust: Write scalable load tests in plain Python}},
url = {https://github.com/locustio/locust},
urldate = {2023-03-27}
}
@inproceedings{Sergeev2022,
abstract = {At the moment, Docker technology is becoming more prevalent in the Windows environment. The pertinent topic in this regard is how Docker containers running on the Windows operating system would behave in the event of a resource deficit. The article discusses circumstances in which there is insufficient processor or RAM to service all running containers. It is proposed to employ stress and volume testing to investigate the stability and reliability of Docker containers. The purpose of stress testing is to determine how the system behaves when the load on the application is greatly increased in comparison to what was initially expected. By delivering enormous amounts of data for processing, volume testing is accomplished. To assess container performance during stress testing, a Prometheus-based technology stack is used. Docker containers running in a Windows system have been shown to operate predictably under extreme load conditions. As the processor load increases, the performance of the containerized program drops proportionately to the decrease in processor time allocated. When there is insufficient RAM to run all containers, Docker uses virtual memory to dynamically distribute memory amongst containers. If a container's execution is halted due to a lack of available RAM on the system, the container's execution is terminated. Other containers continue to function normally.},
author = {Sergeev, A. and Rezedinova, E. and Khakhina, A.},
booktitle = {Journal of Physics: Conference Series},
doi = {10.1088/1742-6596/2339/1/012010},
file = {:home/magnus/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sergeev, Rezedinova, Khakhina - 2022 - Stress testing of Docker containers running on a Windows operating system.pdf:pdf},
issn = {17426596},
number = {1},
publisher = {Institute of Physics},
title = {{Stress testing of Docker containers running on a Windows operating system}},
volume = {2339},
year = {2022}
}
@article{Zeng,
abstract = {With the demand of agile development and management , cloud applications today are moving towards a more fine-grained microservice paradigm, where smaller and simpler functioning parts are combined for providing end-to-end services. In recent years, we have witnessed many research efforts that strive to optimize the performance of cloud computing system in this new era. This paper provides an overview of existing works on recent system performance optimization techniques and classify them based on their design focuses. We also identify open issues and challenges in this important research direction.},
author = {Zeng, Rong and Hou, Xiaofeng and Zhang, Lu and Zheng, Wenli and Guo, Minyi},
doi = {10.1007/s11704-020-0072-3},
file = {::},
keywords = {challenges,cloud computing system,microservice,opportunities,perfor-mance optimization},
title = {{Performance optimization for cloud computing systems in the microservice era: state-of-the-art and research opportunities}},
url = {https://doi.org/10.1007/s11704-020-0072-3}
}
@article{Gan2019,
abstract = {Cloud services have recently started undergoing a major shift from monolithic applications, to graphs of hundreds of loosely-coupled microservices. Microservices fundamentally change a lot of assumptions current cloud systems are designed with, and present both opportunities and challenges when optimizing for quality of service (QoS) and utilization. In this paper we explore the implications microservices have across the cloud system stack. We first present Death- StarBench, a novel, open-source benchmark suite built with microservices that is representative of large end-to-end services, modular and extensible. DeathStarBench includes a social network, a media service, an e-commerce site, a banking system, and IoT applications for coordination control of UAV swarms. We then use DeathStarBench to study the architectural characteristics of microservices, their implications in networking and operating systems, their challenges with respect to cluster management, and their trade-offs in terms of application design and programming frameworks. Finally, we explore the tail at scale effects of microservices in real deployments with hundreds of users, and highlight the increased pressure they put on performance predictability.},
author = {Gan, Yu and Zhang, Yanqi and Cheng, Dailun and Shetty, Ankitha and Rathi, Priyal and Katarki, Nayan and Bruno, Ariana and Hu, Justin and Ritchken, Brian and Jackson, Brendon and Hu, Kelvin and Pancholi, Meghna and He, Yuan and Clancy, Brett and Colen, Chris and Wen, Fukang and Leung, Catherine and Wang, Siyuan and Zaruvinsky, Leon and Espinosa, Mateo and Lin, Rick and Liu, Zhongling and Padilla, Jake and Delimitrou, Christina},
doi = {10.1145/3297858.3304013},
file = {:home/magnus/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gan et al. - 2019 - An Open-Source Benchmark Suite for Microservices and Their Hardware-Software Implications for Cloud {\&} Edge Systems.pdf:pdf},
isbn = {9781450362405},
journal = {International Conference on Architectural Support for Programming Languages and Operating Systems - ASPLOS},
keywords = {QoS,acceleration,cloud computing,cluster management,datacenters,fpga,microservices,serverless},
pages = {3--18},
title = {{An Open-Source Benchmark Suite for Microservices and Their Hardware-Software Implications for Cloud {\&} Edge Systems}},
year = {2019}
}
@misc{ITS,
abstract = {An application in which the user interface, business rules, and data access code is combined into a single executable program and deployed on one platform. A monolithic application operates independently from other applications, performing every step of the process needed to complete the entire business function. It does not share any logic or data across system or organizational boundaries. Databases are designed for access by single application systems within a single agency, not for access by multiple application systems in multiple agencies simultaneously.},
author = {ITS},
title = {{Glossary}},
url = {https://web.archive.org/web/20070902151937/http://www.its.state.nc.us/Information/Glossary/Glossm.asp},
urldate = {2023-03-27},
year = {2001}
}
@article{Gropp2011,
abstract = {The performance of parallel scientific applications depends on many factors which are determined by the execution environment and the parallel application. Especially on large parallel systems, it is too expensive to explore the solution space with series of experiments. Deriving analytical models for applications and platforms allow estimating and extrapolating their execution performance, bottlenecks, and the potential impact of optimization options. We propose to use such "performance modeling" techniques beginning from the application design process throughout the whole software development cycle and also during the lifetime of supercomputer systems. Such models help to guide supercomputer system design and re-engineering efforts to adopt applications to changing platforms and allow users to estimate costs to solve a particular problem. Models can often be built with the help of well-known performance profiling tools. We discuss how we successfully used modeling throughout the proposal, initial testing, and beginning deployment phase of the Blue Waters supercomputer system. Copyright 2011 ACM.},
author = {Hoefler, Torsten and Gropp, William and Snir, Marc and Kramer, William},
doi = {10.1145/2063348.2063356},
file = {:home/magnus/Documents/Master/Performance related articles/Performance{\_}modeling{\_}for{\_}systematic{\_}performance{\_}tuning.pdf:pdf},
isbn = {9781450311397},
journal = {State of the Practice Reports, SC'11},
publisher = {IEEE},
title = {{Performance modeling for systematic performance tuning}},
year = {2011}
}
@article{Gan2018,
abstract = {Performance unpredictability in cloud services leads to poor user experience, degraded availability, and has revenue ramifications. Detecting performance degradation a posteriori helps the system take corrective action, but does not avoid the QoS violations. Detecting QoS violations after the fact is even more detrimental when a service consists of hundreds of thousands of loosely-coupled microservices, since performance hiccups can quickly propagate across the dependency graph of microservices. In this work we focus on anticipating QoS violations in cloud settings to mitigate performance unpredictability to begin with. We propose Seer, a cloud runtime that leverages the massive amount of tracing data cloud systems collect over time and a set of practical learning techniques to signal upcoming QoS violations, as well as identify the microservice(s) causing them. Once an imminent QoS violation is detected Seer uses machine-level hardware events to determine the cause of the QoS violation, and adjusts the resource allocations to prevent it. In local clusters with 10 40-core servers and 200-instance clusters on GCE running diverse cloud microservices, we show that Seer correctly anticipates QoS violations 91{\%} of the time, and attributes the violation to the correct microservice in 89{\%} of cases. Finally, Seer detects QoS violations early enough for a corrective action to almost always be applied successfully.},
author = {Gan, Yu and Pancholi, Meghna and Cheng, Dailun and Hu, Siyuan and He, Yuan and Delimitrou, Christina},
file = {::},
isbn = {9781450362405},
journal = {10th USENIX Workshop on Hot Topics in Cloud Computing, HotCloud 2018, co-located with USENIX ATC 2018},
keywords = {acm reference format,bugging,cloud computing,cloud computing, datacenter, performance debugging,data mining,datacenter,deep learning,ing,microservices,monitor-,performance de-,qos,resource management,tracing},
pages = {19--33},
title = {{Seer: Leveraging big data to navigate the complexity of cloud debugging}},
year = {2018}
}
