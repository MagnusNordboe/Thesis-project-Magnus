{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import requests\n",
    "import datetime\n",
    "\n",
    "\"\"\"\n",
    "A simple program to print the result of a Prometheus query as CSV.\n",
    "\"\"\"\n",
    "def query_csv(q, comment):\n",
    "    # if len(sys.argv) != 3:\n",
    "    #     print('Usage: {0} http://prometheus:9090 a_query'.format(sys.argv[0]))\n",
    "    #     sys.exit(1)\n",
    "\n",
    "    response = requests.get('http://localhost:9090/api/v1/query',\n",
    "            params={'query': q})\n",
    "    results = response.json()['data']['result']\n",
    "\n",
    "    # Build a list of all labelnames used.\n",
    "    labelnames = set()\n",
    "    for result in results:\n",
    "        labelnames.update(result['metric'].keys())\n",
    "\n",
    "    # Canonicalize\n",
    "    labelnames = sorted(labelnames)\n",
    "\n",
    "    with open('test.csv', mode='a') as f:\n",
    "        writer = csv.writer(f)\n",
    "        # Write the header,\n",
    "        writer.writerow(['time:', str(datetime.datetime.now()), 'comment:',comment])\n",
    "        writer.writerow(['name', 'timestamp', 'value'] + labelnames)\n",
    "\n",
    "        # Write the samples.\n",
    "        for result in results:\n",
    "            l = [result['metric'].get('__name__', '')] + result['value']\n",
    "            for label in labelnames:\n",
    "                l.append(result['metric'].get(label, ''))\n",
    "            writer.writerow(l)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import requests\n",
    "from datetime import datetime, timedelta \n",
    "from time import mktime\n",
    "\n",
    "def query_csv_timeseries(q,state, time, step, filename):\n",
    "\n",
    "    #generate timestamp + query\n",
    "    now = datetime.now()\n",
    "    now_unix =  mktime(now.timetuple())\n",
    "\n",
    "    response = requests.get('http://localhost:9090/api/v1/query_range',\n",
    "            params= {'query': q, 'start': now_unix - 3600 * time, \"end\": now_unix, \"step\": step})\n",
    "    results = response.json()['data']['result']\n",
    "    # Build a list of all labelnames used.\n",
    "    labelnames = set()\n",
    "    for result in results:\n",
    "        labelnames.update(result['metric'].keys())\n",
    "\n",
    "\n",
    "    # Canonicalize\n",
    "    labelnames = sorted(labelnames)\n",
    "    # print(labelnames)\n",
    "    # print(result[\"values\"])\n",
    "\n",
    "    # with open( q + \"_\" + state + '.csv', mode='a') as f:\n",
    "    with open(filename + '.csv', mode='a') as f:\n",
    "        writer = csv.writer(f)\n",
    "        # Write the header,\n",
    "        #writer.writerow(labelnames)\n",
    "\n",
    "        #Write the samples.\n",
    "        for result in results:\n",
    "            l = [result['metric'].get('__name__', '')] + result['values']\n",
    "            \n",
    "            #Prune the first element in each list, which is just a unix timestamp\n",
    "            vals = [x[1] for x in result['values']]\n",
    "            identifier_string = \"\"\n",
    "            for label in labelnames:\n",
    "                identifier_string += result['metric'].get(label, '') + \"&\"\n",
    "                #l.append(result['metric'].get(label, ''))\n",
    "                #writer.writerow(l)\n",
    "                #print(l , \"lllllll\")\n",
    "            #for label in labelnames:\n",
    "                \n",
    "            writer.writerow([identifier_string[:-1]] + vals)\n",
    "\n",
    "metric = \"jvm_memory_bytes_used\"\n",
    "state = \"testing_2\"\n",
    "time = 0.2\n",
    "step = \"5m\"\n",
    "#query_csv_timeseries(metric, state, time, step)\n",
    "\n",
    "#CSV BUilding. Put identifying information into one complete string as first element in each row. Then prune the timestamps to get only the numbers and put those into the csv \n",
    "#Put eerything in identifying string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def query_collection(time, step, source, filename):\n",
    "    file = open(source)\n",
    "    metrics = json.load(file)['data']\n",
    "\n",
    "    for i in metrics:\n",
    "        query_csv_timeseries(i, \"testing\", time, step, filename)\n",
    "\n",
    "    \n",
    "\n",
    "#query_collection(9, \"1m\", \"metrics.json\", \"heavy_load_4hv4\")\n",
    "query_collection(7, \"1m\", \"metrics.json\", \"heavy_load_1m_stacked\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Every 1 hour do doImports() (last run: [never], next run: 2022-12-11 00:15:25)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import schedule\n",
    "import time\n",
    "\n",
    "def doImports():\n",
    "    query_collection(5, \"1m\", \"metrics.json\", \"heavy_load_dunno_but_its_been_a_while_ill_find_out_hehe\")\n",
    "    print(\"running\")\n",
    "\n",
    "schedule.every(1).hours.do(doImports)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1669892339.0 1669885139.0 1669885139.0\n"
     ]
    }
   ],
   "source": [
    "#query_csv('avg by (job, instance, mode) (rate(process_cpu_seconds_total[5m]))', 'test1 after setup')\n",
    "from datetime import datetime, timedelta \n",
    "from time import mktime\n",
    "now = datetime.now()\n",
    "twhoursago = now - timedelta(hours=2)\n",
    "now_unix = mktime(now.timetuple())\n",
    "twhoursago_unix = mktime(twhoursago.timetuple())\n",
    "twhoursago_unix_manual = now_unix - 7200\n",
    "print(now_unix, twhoursago_unix, twhoursago_unix_manual)\n",
    "# node_cpu_seconds_total&start=2022-09-07T00:00:00Z&end=2022-09-07T02:00:00Z&step=5m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "976 239 380\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "with open('heavy_load_1m_stacked.csv') as obj:\n",
    "    reader = csv.reader(obj)\n",
    "    list_of_csv = list(reader)\n",
    "    useless_metrics = list()\n",
    "    delta_metrics = list()\n",
    "    metrics = list()\n",
    "\n",
    "    for mlist in list_of_csv:\n",
    "        if(mlist == []):\n",
    "            continue\n",
    "        label = mlist.pop(0)\n",
    "        equal = all(i == j for i, j in zip(mlist, mlist[1:]))\n",
    "        if equal:\n",
    "            useless_metrics.append(label)\n",
    "            continue\n",
    "        res = all(i <= j for i, j in zip(mlist, mlist[1:]))\n",
    "        if res:\n",
    "            delta_metrics.append(label)\n",
    "            continue\n",
    "        metrics.append(label)\n",
    "    print(len(useless_metrics), len(delta_metrics), len(metrics))\n",
    "    with open(\"sorted_metrics.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump({\n",
    "            \"delta_metrics\": delta_metrics,\n",
    "            \"metrics\": metrics,\n",
    "            \"useless_metrics\": useless_metrics\n",
    "        }, f, ensure_ascii=False, indent=4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ecabe05d72c87138abd5588a1756d674ee9acb6f0f71aa26006671d9984b5b0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
